{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to mpmakris@gmail.com and will expire on June 30, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1470536484.log\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gl.set_runtime_config('GRAPHLAB_DEFAULT_NUM_PYLAMBDA_WORKERS', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT TARGET INFO FROM PREPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_prepper(file_path):\n",
    "    \"\"\"Open the DataPrepper from pickled file.\"\"\"\n",
    "    with open(file_path) as f:\n",
    "        prepper = pickle.load(f)\n",
    "    return prepper\n",
    "\n",
    "file_path = '../data/store/data_prepper_BUILDING.pkl'\n",
    "prepper = open_prepper(file_path)\n",
    "\n",
    "X_train, y_train = prepper.return_training_data()\n",
    "X_test, y_test = prepper.return_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_combined = pd.concat((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(y_combined['image_views_quantized'], bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH LAB IMPORT IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_raw = gl.image_analysis.load_images('/home/ubuntu/data/images/BUILDING/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = images_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images['filename'] = images['path'].apply(lambda x: x[x.find('/')+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check = True\n",
    "while check:\n",
    "    images['filename'] = images['filename'].apply(lambda x: x[x.find('/')+1:])\n",
    "    if images[0]['filename'].find('/') < 0:\n",
    "        check = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images['owner'] = images['filename'].apply(lambda x: x[:x.find('_')])\n",
    "images['id'] = images['filename'].apply(lambda x: x[x.find('_')+1:])\n",
    "images['id'] = images['id'].apply(lambda x: x[:x.find('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images.remove_columns(['path', 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images.column_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images['id'] = images['id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMBINE IMAGES WITH TARGET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_combined.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = gl.SFrame(data=y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = images.join(target, on=['owner', 'id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images['user_is_pro'] = images['user_is_pro'].apply(lambda x: int(x))\n",
    "images['user_can_buy_pro'] = images['user_can_buy_pro'].apply(lambda x: int(x))\n",
    "images['user_total_views'] = images['user_total_views'].apply(lambda x: int(x))\n",
    "images['image_views'] = images['image_views'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESIZE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images['resized_image'] = gl.image_analysis.resize(images['image'], 800, 600, channels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "extractor = gl.feature_engineering.DeepFeatureExtractor(features='resized_image', output_column_prefix='deep_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "extractor = extractor.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "extracted_model = extractor['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "images = extractor.transform(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data, then Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images.save('/home/ubuntu/data/GL_BUILDINGS_MODELING_DATA_RESIZED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">owner</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">user_is_pro</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">user_can_buy_pro</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">user_total_views</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_ncomments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 1066 Width: 1600</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">49503002894@N01</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20924375303</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">106299.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_nfavs</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_nsets</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_npools</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_views</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_views_quantized</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">user_total_views_quantize<br>d ...</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_nfavs_quantized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">41.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_ncomments_quantized</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_nsets_quantized</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">image_npools_quantized</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">resized_image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Height: 600 Width: 800</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[1 rows x 18 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\timage\tImage\n",
       "\towner\tstr\n",
       "\tid\tint\n",
       "\tuser_is_pro\tfloat\n",
       "\tuser_can_buy_pro\tfloat\n",
       "\tuser_total_views\tfloat\n",
       "\timage_ncomments\tint\n",
       "\timage_nfavs\tfloat\n",
       "\timage_nsets\tint\n",
       "\timage_npools\tint\n",
       "\timage_views\tfloat\n",
       "\timage_views_quantized\tint\n",
       "\tuser_total_views_quantized\tint\n",
       "\timage_nfavs_quantized\tint\n",
       "\timage_ncomments_quantized\tint\n",
       "\timage_nsets_quantized\tint\n",
       "\timage_npools_quantized\tint\n",
       "\tresized_image\tImage\n",
       "\n",
       "Rows: 1\n",
       "\n",
       "Data:\n",
       "+--------------------------+-----------------+-------------+-------------+------------------+\n",
       "|          image           |      owner      |      id     | user_is_pro | user_can_buy_pro |\n",
       "+--------------------------+-----------------+-------------+-------------+------------------+\n",
       "| Height: 1066 Width: 1600 | 49503002894@N01 | 20924375303 |     1.0     |       0.0        |\n",
       "+--------------------------+-----------------+-------------+-------------+------------------+\n",
       "+------------------+-----------------+-------------+-------------+--------------+\n",
       "| user_total_views | image_ncomments | image_nfavs | image_nsets | image_npools |\n",
       "+------------------+-----------------+-------------+-------------+--------------+\n",
       "|     106299.0     |        0        |     0.0     |      1      |      0       |\n",
       "+------------------+-----------------+-------------+-------------+--------------+\n",
       "+-------------+-----------------------+----------------------------+-----------------------+\n",
       "| image_views | image_views_quantized | user_total_views_quantized | image_nfavs_quantized |\n",
       "+-------------+-----------------------+----------------------------+-----------------------+\n",
       "|     41.0    |           2           |             5              |           1           |\n",
       "+-------------+-----------------------+----------------------------+-----------------------+\n",
       "+---------------------------+-----------------------+------------------------+\n",
       "| image_ncomments_quantized | image_nsets_quantized | image_npools_quantized |\n",
       "+---------------------------+-----------------------+------------------------+\n",
       "|             1             |           1           |           1            |\n",
       "+---------------------------+-----------------------+------------------------+\n",
       "+------------------------+\n",
       "|     resized_image      |\n",
       "+------------------------+\n",
       "| Height: 600 Width: 800 |\n",
       "+------------------------+\n",
       "[1 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train, images_test = images.random_split(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD MODEL IF NEED BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = gl.load_sframe('/home/ubuntu/data/GL_BUILDINGS_MODELING_DATA_RESIZED')\n",
    "#images_train, images_test = images.random_split(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEURAL NET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = gl.neuralnet_classifier.create(images_train, target='user_is_pro', features=['resized_image'],\n",
    "                                         max_iterations=100, network=None, validation_set=images_test,\n",
    "                                         class_weights='auto', metric='auto', random_crop=False,\n",
    "                                         input_shape=None, random_mirror=False, learning_rate=0.001, momentum=0.9,\n",
    "                                         l2_regularization=0.0005, bias_l2_regularization=0.0, init_random='gaussian',\n",
    "                                         init_sigma=0.01, init_bias=0.0,\n",
    "                                         model_checkpoint_path='/home/ubuntu/data/GL_BUILDINGS_MODEL_CHECKPOINT',\n",
    "                                         model_checkpoint_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_network_layers = list()\n",
    "#cust_network_layers.append(gl.deeplearning.layers.FlattenLayer())\n",
    "cust_network_layers.append(gl.deeplearning.layers.FullConnectionLayer(100, init_sigma=0.5))\n",
    "cust_network_layers.append(gl.deeplearning.layers.RectifiedLinearLayer())\n",
    "cust_network_layers.append(gl.deeplearning.layers.DropoutLayer(0.5))\n",
    "cust_network_layers.append(gl.deeplearning.layers.FullConnectionLayer(200, init_sigma=.1))\n",
    "cust_network_layers.append(gl.deeplearning.layers.TanhLayer())\n",
    "cust_network_layers.append(gl.deeplearning.layers.FullConnectionLayer(150, init_sigma=.1))\n",
    "cust_network_layers.append(gl.deeplearning.layers.TanhLayer())\n",
    "cust_network_layers.append(gl.deeplearning.layers.FullConnectionLayer(2, init_sigma=0.5))\n",
    "cust_network_layers.append(gl.deeplearning.layers.SoftmaxLayer())\n",
    "\n",
    "custom_network = gl.deeplearning.NeuralNet()\n",
    "#custom_network.params['max_iterations'] = 20\n",
    "custom_network.layers = cust_network_layers\n",
    "custom_network.verify(input_shape=[1, 1, 4096], output_shape=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_neuralnetclassifier_ispro = gl.neuralnet_classifier.create(images_train, target='user_is_pro',\n",
    "                                                                 features=['deep_.resized_image'],\n",
    "                                                                 network=custom_network, max_iterations=100,\n",
    "                                                                 validation_set=images_test, batch_size=1000,\n",
    "                                                                 model_checkpoint_path='neural_network_model',\n",
    "                                                                 model_checkpoint_interval=5\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_neuralnetclassifier_ispro.extract_features() # WHAT IS THIS?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuralnetclassifier_results = model_neuralnetclassifier_ispro.evaluate(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuralnetclassifier_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuralnetclassifier_results['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuralnetclassifier_results['confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_test_predictions = model_neuralnetclassifier_ispro.predict(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(nn_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl.deeplearning.get_builtin_neuralnet('imagenet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

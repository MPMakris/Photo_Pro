{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, LogisticRegressionCV, Lasso, Ridge, RidgeClassifier, SGDClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, precision_recall_fscore_support, f1_score, r2_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint as sp_randint, gamma as sp_gamma, expon as sp_expon, uniform as sp_uniform\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('../data/modeling/SPORTS/feature_data_SPORTS_21205.csv', sep='|')\n",
    "df_targets = pd.read_csv('../data/modeling/SPORTS/target_data_SPORTS_21205.csv', sep='|')\n",
    "\n",
    "df_features = df_features.set_index('owner').set_index(\"id\", append=True)\n",
    "\n",
    "df_targets = df_targets.set_index('owner').set_index(\"id\", append=True)\n",
    "\n",
    "df_targets = df_targets.drop('image_tags', axis=1)\n",
    "\n",
    "target_columns = list(df_targets.columns)\n",
    "target_columns.remove('image_ntags')\n",
    "target_columns\n",
    "\n",
    "df = df_features.join(df_targets, how='inner')\n",
    "\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_quantile(x, limits):\n",
    "    quantile_cats = range(1, len(limits)+1, 1)\n",
    "    for cat, limit in zip(quantile_cats, limits):\n",
    "        if x <= limit:\n",
    "            return cat\n",
    "\n",
    "def create_quantile_target_col(df_train, df_test, target_columns, col_name, n_quantiles=5):\n",
    "    \"\"\"\n",
    "    Create a new column in both DataFrames that bins a target column into categories.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df_train : pandas.DataFrame\n",
    "        The training set data.\n",
    "        \n",
    "    df_test : pandas.DataFrame\n",
    "        The testint set data.\n",
    "    \n",
    "    n_quantiles : int\n",
    "        The number of bins. For 4 bins (0 to 0.25, 0.25 to 0.5, etc...), n_quantiles=4.\n",
    "        \n",
    "    col_name : str\n",
    "    \n",
    "    target_columns : list\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    df : DataFrame\n",
    "    \n",
    "    target_columns : list        \n",
    "    \"\"\"\n",
    "    min_value = df_train[col_name].min()\n",
    "    max_value = df_train[col_name].max()\n",
    "    limits = []\n",
    "    for i in range(1, n_quantiles+1):\n",
    "        limits.append(df_train[col_name].quantile(i/float(n_quantiles)))\n",
    "    \n",
    "    new_col_name = col_name+\"_quantile\"\n",
    "    target_columns.append(new_col_name)\n",
    "    \n",
    "    df_train.loc[:, new_col_name] = df_train[col_name].apply(lambda x: name_quantile(x, limits))\n",
    "    df_test.loc[:, new_col_name] = df_test[col_name].apply(lambda x: name_quantile(x, limits))\n",
    "    return df_train, df_test, target_columns\n",
    "\n",
    "def pop_columns(df, col_names):\n",
    "    for i, name in enumerate(list(col_names)):\n",
    "        if i == 0:\n",
    "            df_dropped_cols = df.pop(name)\n",
    "        else:\n",
    "            df_dropped_cols = pd.concat((df_dropped_cols, df.pop(name)), axis=1)\n",
    "    return df, df_dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_views', 4)\n",
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_ncomments', 4)\n",
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_nfavs', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = pop_columns(df_train, target_columns)\n",
    "X_test, y_test = pop_columns(df_test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_columns = X_train.columns\n",
    "y_columns = y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_mean_std = StandardScaler()\n",
    "X_train = scaler_mean_std.fit_transform(X_train)\n",
    "X_test = scaler_mean_std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=X_train, columns=X_columns)\n",
    "X_test = pd.DataFrame(data=X_test, columns=X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_is_pro</th>\n",
       "      <th>user_can_buy_pro</th>\n",
       "      <th>user_total_views</th>\n",
       "      <th>image_ncomments</th>\n",
       "      <th>image_nfavs</th>\n",
       "      <th>image_nsets</th>\n",
       "      <th>image_npools</th>\n",
       "      <th>image_views</th>\n",
       "      <th>image_views_quantile</th>\n",
       "      <th>image_ncomments_quantile</th>\n",
       "      <th>image_nfavs_quantile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12385792@N00</th>\n",
       "      <th>11378305226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user_is_pro  user_can_buy_pro  user_total_views  \\\n",
       "owner        id                                                             \n",
       "12385792@N00 11378305226            1                 0              7760   \n",
       "\n",
       "                          image_ncomments  image_nfavs  image_nsets  \\\n",
       "owner        id                                                       \n",
       "12385792@N00 11378305226                0            0            1   \n",
       "\n",
       "                          image_npools  image_views  image_views_quantile  \\\n",
       "owner        id                                                             \n",
       "12385792@N00 11378305226             0            6                     1   \n",
       "\n",
       "                          image_ncomments_quantile  image_nfavs_quantile  \n",
       "owner        id                                                           \n",
       "12385792@N00 11378305226                         1                     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image Views Quantile (IVQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_distributions = {'Logistic': {\"C\": sp_expon(loc=0.001, scale=1),\n",
    "                                    \"fit_intercept\": [True, False],\n",
    "                                    \"intercept_scaling\": sp_randint(1, 5),\n",
    "                                    \"warm_start\": [False, True]\n",
    "                                    },\n",
    "                       'RandomForest': {\"max_depth\": sp_randint(2, 7),\n",
    "                                        \"max_features\": ['auto', None],\n",
    "                                        \"min_samples_split\": sp_randint(1, 201),\n",
    "                                        \"min_samples_leaf\": sp_randint(1, 201),\n",
    "                                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "                                        \"oob_score\": True,\n",
    "                                        \"warm_start\": [False, True] \n",
    "                                        },\n",
    "                       'AdaBoost_DT': {\"learning_rate\": sp_expon(loc=0.001, scale=1.5),\n",
    "                                       \"algorithm\" : ['SAMME.R', 'SAMME']\n",
    "                                       },\n",
    "                       'GBC': {\"learning_rate\": sp_expon(loc=0.001, scale=0.5),\n",
    "                               \"subsample\": sp_uniform(loc=0.2, scale=1.0),\n",
    "                               \"max_features\": [None, 'auto'],\n",
    "                               \"warm_start\": [True, False]\n",
    "                               },\n",
    "                       'SVC': {\"C\": sp_expon(loc=0.001, scale=2),\n",
    "                               \"kernel\": ['rbf', 'poly'],\n",
    "                               \"degree\": sp_randint(2, 10),\n",
    "                               \"coef0\": [0, 1, 2],\n",
    "                               \"shrinking\": [True, False]\n",
    "                               }\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, min_samples_split=10, min_samples_leaf=10,\n",
    "      min_weight_fraction_leaf=0.0, max_features=300, random_state=30, max_leaf_nodes=20, class_weight=None,\n",
    "      presort=False)\n",
    "\n",
    "model_ivq_LogitClassifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001,\n",
    "                                               class_weight=None, random_state=25,\n",
    "                                               solver='liblinear', max_iter=10, multi_class='ovr', verbose=1,\n",
    "                                               n_jobs=36)\n",
    "\n",
    "model_ivq_RandomForest = RandomForestClassifier(n_estimators=300, min_weight_fraction_leaf=0.0, n_jobs=36,\n",
    "                                                random_state=42, verbose=1, class_weight=None, bootstrap=True)\n",
    "\n",
    "model_ivq_AdaBoost_DT = AdaBoostClassifier(base_estimator=DT, n_estimators=50, random_state=12)\n",
    "\n",
    "model_ivq_GBC = GradientBoostingClassifier(loss='deviance', n_estimators=50,\n",
    "                                           min_samples_split=10, min_samples_leaf=10, min_weight_fraction_leaf=0.0,\n",
    "                                           max_depth=3, random_state=21, verbose=2,\n",
    "                                           max_leaf_nodes=12, presort='auto')\n",
    "\n",
    "model_ivq_SVC = SVC(gamma='auto', probability=True,\n",
    "                    tol=0.001, cache_size=1000, class_weight=None, verbose=True, max_iter=20,\n",
    "                    decision_function_shape='ovr', random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False \n",
      "[CV] warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False \n",
      "[CV] warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False \n",
      "[CV] warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False \n",
      "[CV] warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False \n",
      "[CV] warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False \n",
      "[CV] warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False \n",
      "[CV] warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False \n",
      "[CV] warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False \n",
      "[CV] warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False - 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False - 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False - 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False - 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=3.21002324315, intercept_scaling=2, fit_intercept=False - 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False - 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False - 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False - 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False - 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV]  warm_start=True, C=0.909077971371, intercept_scaling=3, fit_intercept=False - 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=36,\n",
       "          penalty='l2', random_state=25, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=2, n_jobs=36,\n",
       "          param_distributions={'warm_start': [False, True], 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff47109da10>, 'intercept_scaling': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff47109dc10>, 'fit_intercept': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "random_search_LogitClassifier = RandomizedSearchCV(estimator=model_ivq_LogitClassifier,\n",
    "                                                   param_distributions=param_distributions['Logistic'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=2, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_LogitClassifier.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.51515, std: 0.00740, params: {'warm_start': True, 'C': 0.9090779713708561, 'intercept_scaling': 3, 'fit_intercept': False},\n",
       " mean: 0.51368, std: 0.00800, params: {'warm_start': True, 'C': 3.210023243149706, 'intercept_scaling': 2, 'fit_intercept': False}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_LogitClassifier.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51514972883753829"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_LogitClassifier.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logit Classifier F1 Score:  0.514739874928\n"
     ]
    }
   ],
   "source": [
    "best_LogitClassifier = random_search_LogitClassifier.best_estimator_\n",
    "y_pred = best_LogitClassifier.predict(X_test)\n",
    "print \"Best Logit Classifier F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] warm_start=True, oob_score=True, min_samples_leaf=131, max_features=None, criterion=entropy, min_samples_split=192, max_depth=3 \n",
      "[CV] warm_start=True, oob_score=True, min_samples_leaf=131, max_features=None, criterion=entropy, min_samples_split=192, max_depth=3 \n",
      "[CV] warm_start=False, oob_score=True, min_samples_leaf=120, max_features=auto, criterion=gini, min_samples_split=190, max_depth=5 \n",
      "[CV] warm_start=False, oob_score=True, min_samples_leaf=120, max_features=auto, criterion=gini, min_samples_split=190, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=False, oob_score=True, min_samples_leaf=120, max_features=auto, criterion=gini, min_samples_split=190, max_depth=5 -  48.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=False, oob_score=True, min_samples_leaf=120, max_features=auto, criterion=gini, min_samples_split=190, max_depth=5 -  49.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:  7.9min finished\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:  7.9min finished\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=True, oob_score=True, min_samples_leaf=131, max_features=None, criterion=entropy, min_samples_split=192, max_depth=3 - 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  warm_start=True, oob_score=True, min_samples_leaf=131, max_features=None, criterion=entropy, min_samples_split=192, max_depth=3 - 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done   4 out of   4 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=36,\n",
       "            oob_score=False, random_state=42, verbose=1, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=2, n_jobs=36,\n",
       "          param_distributions={'warm_start': [False, True], 'oob_score': [False, True], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4599082d0>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff459908310>, 'criterion': ['gini', 'entropy'], 'max_features': ['auto', None], 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4598fd3d0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "random_search_RandomForest = RandomizedSearchCV(estimator=model_ivq_RandomForest,\n",
    "                                                param_distributions=param_distributions['RandomForest'],\n",
    "                                                n_iter=n_iter_search,\n",
    "                                                n_jobs=36, cv=2, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_RandomForest.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52699834944588542"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_RandomForest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=36)]: Done 378 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=36)]: Done 728 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Classifier F1 Score:  0.498109252463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "best_RandomForest = random_search_RandomForest.best_estimator_\n",
    "y_pred = best_RandomForest.predict(X_test)\n",
    "print \"Best Random Forest Classifier F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost DT Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done   6 out of   6 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=300, max_leaf_nodes=20, min_samples_leaf=10,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=30, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=12),\n",
       "          fit_params={}, iid=True, n_iter=2, n_jobs=36,\n",
       "          param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4a92abc10>, 'algorithm': ['SAMME.R', 'SAMME']},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "random_search_AdaBoost_DT = RandomizedSearchCV(estimator=model_ivq_AdaBoost_DT,\n",
    "                                                   param_distributions=param_distributions['AdaBoost_DT'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=3, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_AdaBoost_DT.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59643951898137226"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_AdaBoost_DT.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost DT F1 Score:  0.607472223011\n"
     ]
    }
   ],
   "source": [
    "best_AdaBoost_DT = random_search_AdaBoost_DT.best_estimator_\n",
    "y_pred = best_AdaBoost_DT.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Classifier Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False \n",
      "[CV] max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False \n",
      "[CV] max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False \n",
      "[CV] max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False \n",
      "[CV] max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "[CV] max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        4781.7885        1244.1698            2.90m\n",
      "         1        4805.6573        1248.7172            2.85m\n",
      "         1        4771.3900        1293.6045            2.78m\n",
      "         1        7679.2944        1244.0948            4.01m\n",
      "         1        7608.1088        1398.7393            4.10m\n",
      "         1        7617.7470        1357.8027            4.23m\n",
      "         2        4382.0788         674.7791            2.74m\n",
      "         2        4405.1305         704.3443            2.76m\n",
      "         2        4317.3737         757.7113            2.76m\n",
      "         3        4092.2555         443.5772            2.66m\n",
      "         3        4082.7333         543.7188            2.69m\n",
      "         2        6819.3752         381.9383            3.94m\n",
      "         3        4006.9239         467.8441            2.68m\n",
      "         2        6836.8411         376.9240            3.94m\n",
      "         2        6760.4590         383.5047            4.06m\n",
      "         4        3897.9437         358.6547            2.62m\n",
      "         4        3840.1839         370.6117            2.62m\n",
      "         4        3838.9992         348.6607            2.61m\n",
      "         3        6412.1348         204.8891            3.81m\n",
      "         3        6225.3581         226.5570            3.82m\n",
      "         3        6209.7945         232.2773            3.94m\n",
      "         5        3737.5044         320.0678            2.57m\n",
      "         5        3701.5413         238.3437            2.54m\n",
      "         5        3718.4870         227.7667            2.56m\n",
      "         4        5998.2520         105.6036            3.72m\n",
      "         6        3569.0083         154.2696            2.49m\n",
      "         4        5945.6747         107.5057            3.70m\n",
      "         6        3558.0528         215.2957            2.47m\n",
      "         6        3555.4044         193.3295            2.52m\n",
      "         4        5955.6409          81.5334            3.89m\n",
      "         7        3489.8190         114.3729            2.38m\n",
      "         7        3448.7958         178.6390            2.42m\n",
      "         7        3418.6397         159.7528            2.43m\n",
      "         5        5830.5347          47.3302            3.62m\n",
      "         5        5691.0373          73.9547            3.62m\n",
      "         8        3400.7660          92.5273            2.31m\n",
      "         8        3377.6594         129.2047            2.36m\n",
      "         5        5746.0060          76.8871            3.83m\n",
      "         8        3366.1325         110.1494            2.37m\n",
      "         6        5641.5870          17.0686            3.51m\n",
      "         9        3290.8296          92.2343            2.26m\n",
      "         9        3287.3008          60.8599            2.28m\n",
      "         6        5422.3101          61.1729            3.54m\n",
      "         9        3225.3267          83.1071            2.29m\n",
      "         6        5523.5799          37.7629            3.70m\n",
      "        10        3231.0251          87.5091            2.19m\n",
      "        10        3260.9575          43.1353            2.22m\n",
      "        10        3226.9998          65.2395            2.22m\n",
      "         7        5500.3072          20.7929            3.42m\n",
      "         7        5351.9844          19.1866            3.42m\n",
      "         7        5320.7441          53.6654            3.58m\n",
      "        11        3151.8032          70.9730            2.16m\n",
      "        11        3177.2501          83.0023            2.14m\n",
      "        11        3178.6929          81.0635            2.17m\n",
      "         8        5384.7085          14.4660            3.29m\n",
      "         8        5175.3435           9.7362            3.30m\n",
      "        12        3144.2999          63.9490            2.09m\n",
      "        12        3134.0123          45.4513            2.09m\n",
      "        12        3106.6710          38.8150            2.10m\n",
      "         8        5230.0823          15.8650            3.45m\n",
      "        13        3139.3776          40.2381            2.02m\n",
      "         9        5200.0095          17.4082            3.19m\n",
      "        13        3062.2507          50.7531            2.03m\n",
      "        13        3075.8873          38.4210            2.03m\n",
      "         9        4952.4919          25.5355            3.23m\n",
      "        14        3062.4118          23.5051            1.95m\n",
      "         9        5042.2811           4.6759            3.36m\n",
      "        14        3014.1220          29.8053            1.97m\n",
      "        14        3009.0211          48.9834            1.98m\n",
      "        10        5070.9884          12.4038            3.11m\n",
      "        10        4888.3816           0.6324            3.12m\n",
      "        15        2966.8286          37.8529            1.90m\n",
      "        15        2925.1150          25.8469            1.91m\n",
      "        15        2952.0771          52.8424            1.92m\n",
      "        10        4937.2471          30.9746            3.26m\n",
      "        16        2943.9040          12.0831            1.83m\n",
      "        11        4963.5388           1.6932            3.03m\n",
      "        11        4809.9031          -2.6024            3.03m\n",
      "        16        2981.4191          42.6701            1.85m\n",
      "        16        2948.6555          19.7137            1.86m\n",
      "        17        2970.0652          19.1008            1.77m\n",
      "        11        4764.5069         -10.3199            3.17m\n",
      "        17        2834.6556          26.4658            1.80m\n",
      "        17        2910.7187          10.2548            1.80m\n",
      "        12        4917.9455           9.1324            2.93m\n",
      "        12        4727.0474          18.5592            2.95m\n",
      "        18        2932.0806          12.0837            1.71m\n",
      "        18        2901.7654          12.3172            1.74m\n",
      "        12        4716.4757          -5.9678            3.05m\n",
      "        18        2881.4476          17.1617            1.75m\n",
      "        13        4770.4543           9.8808            2.84m\n",
      "        19        2900.6169          16.1192            1.66m\n",
      "        13        4561.0157          -4.7219            2.87m\n",
      "        19        2860.9408          37.8574            1.68m\n",
      "        19        2822.0206          31.2633            1.69m\n",
      "        13        4586.8919          -7.3225            2.97m\n",
      "        20        2837.6345          36.7248            1.60m\n",
      "        20        2805.4297          -5.5802            1.62m\n",
      "        14        4597.8586          13.2274            2.77m\n",
      "        20        2805.9441           8.2389            1.63m\n",
      "        14        4404.9846           3.1135            2.79m\n",
      "        21        2805.0381          -0.8411            1.55m\n",
      "        21        2748.9866          14.8432            1.56m\n",
      "        14        4479.8164          -9.4538            2.87m\n",
      "        21        2789.7837           2.0330            1.57m\n",
      "        15        4521.9631         -16.9306            2.68m\n",
      "        22        2797.1822           3.8752            1.49m\n",
      "        15        4359.0024          -5.8030            2.70m\n",
      "        22        2761.1919          11.6469            1.50m\n",
      "        22        2703.2777          17.5877            1.51m\n",
      "        15        4400.7273           8.9074            2.79m\n",
      "        23        2846.5211           1.1367            1.43m\n",
      "        16        4472.6146         -16.6286            2.58m\n",
      "        23        2696.5451          14.6773            1.45m\n",
      "        23        2705.1559          22.9305            1.45m\n",
      "        16        4325.3196         -16.3233            2.61m\n",
      "        24        2773.0242           9.6590            1.38m\n",
      "        24        2704.3921           2.3905            1.39m\n",
      "        24        2702.8985          14.7049            1.39m\n",
      "        16        4285.0767          -4.7355            2.71m\n",
      "        17        4394.1890         -15.8134            2.50m\n",
      "        25        2711.9065          25.9441            1.32m\n",
      "        17        4225.5718          -3.5338            2.53m\n",
      "        25        2652.4300          13.0255            1.33m\n",
      "        25        2680.3936           4.1740            1.34m\n",
      "        17        4171.2643          -9.8411            2.62m\n",
      "        18        4310.7331          -8.5905            2.42m\n",
      "        26        2700.0953           7.2197            1.27m\n",
      "        26        2635.0976           4.6381            1.28m\n",
      "        18        4174.2325          -0.1103            2.44m\n",
      "        26        2668.2797           3.1037            1.28m\n",
      "        27        2683.2155          -1.1744            1.22m\n",
      "        27        2629.1432           7.3709            1.22m\n",
      "        18        4136.8020         -15.2664            2.53m\n",
      "        19        4271.5901         -12.6675            2.34m\n",
      "        27        2666.6371           4.2794            1.22m\n",
      "        19        4109.7342         -11.8609            2.36m\n",
      "        28        2655.8667           8.7840            1.16m\n",
      "        28        2592.4700          -0.0552            1.16m\n",
      "        28        2620.8464           7.0949            1.17m\n",
      "        20        4144.2340          -0.1497            2.26m\n",
      "        19        4011.8966           0.2448            2.45m\n",
      "        29        2618.8558          11.1449            1.11m\n",
      "        29        2553.3714           4.1410            1.11m\n",
      "        20        4030.1702          -8.8841            2.28m\n",
      "        29        2583.1860          -1.3575            1.12m\n",
      "        30        2571.5618           6.0396            1.05m\n",
      "        30        2574.9565          13.1664            1.06m\n",
      "        20        3931.7720         -11.8668            2.36m\n",
      "        21        4082.0894          -3.6803            2.19m\n",
      "        30        2616.4779           4.2236            1.06m\n",
      "        21        3917.5453          -9.8986            2.20m\n",
      "        31        2564.3659           7.9090            1.00m\n",
      "        31        2604.5060           5.4476            1.00m\n",
      "        31        2518.0042         -10.1814            1.01m\n",
      "        21        3848.0397         -17.1300            2.27m\n",
      "        22        4011.6648          -8.5972            2.11m\n",
      "        32        2551.0592           3.4622           56.80s\n",
      "        32        2540.3743           9.7228           57.00s\n",
      "        22        3848.9569         -10.3922            2.13m\n",
      "        32        2536.0666          -1.6033           57.20s\n",
      "        33        2505.3827           5.9684           53.47s\n",
      "        33        2511.7360          -2.3188           53.73s\n",
      "        23        3992.2266          -3.6562            2.03m\n",
      "        22        3787.8228         -11.8780            2.20m\n",
      "        33        2486.6925          12.0543           53.94s\n",
      "        23        3877.1087         -16.8791            2.04m\n",
      "        34        2453.3276           9.8487           50.32s\n",
      "        34        2495.8498          -4.2491           50.46s\n",
      "        34        2473.8731           4.5290           50.59s\n",
      "        23        3719.6584           9.4340            2.11m\n",
      "        24        3911.0553           5.6187            1.96m\n",
      "        24        3787.6455         -10.1579            1.96m\n",
      "        35        2479.1163           5.2028           47.24s\n",
      "        35        2435.5844          11.0194           47.18s\n",
      "        35        2503.7339          -3.9859           47.38s\n",
      "        36        2429.2715           8.1573           44.09s\n",
      "        36        2420.8046           6.3033           44.02s\n",
      "        24        3738.1101          -0.9890            2.03m\n",
      "        25        3838.3188         -15.7256            1.88m\n",
      "        36        2471.2705          19.7627           44.18s\n",
      "        25        3676.1435          -0.0222            1.89m\n",
      "        37        2431.8552           7.3925           40.83s\n",
      "        37        2376.1610           6.6209           40.83s\n",
      "        37        2425.2590          -2.2687           41.08s\n",
      "        25        3620.9429         -13.7085            1.94m\n",
      "        26        3770.1768           2.7235            1.80m\n",
      "        26        3556.7956          -5.0010            1.81m\n",
      "        38        2429.0081          -4.6779           37.69s\n",
      "        38        2372.8451          -1.3360           37.64s\n",
      "        38        2411.3607          -2.3493           37.84s\n",
      "        26        3598.7242         -11.7338            1.86m\n",
      "        39        2370.7457          -2.7779           34.52s\n",
      "        27        3720.1069          -6.8308            1.73m\n",
      "        39        2362.7621         -10.2523           34.50s\n",
      "        39        2329.0610          -3.1895           34.66s\n",
      "        27        3550.6785         -12.4521            1.74m\n",
      "        40        2358.4472           0.8610           31.38s\n",
      "        40        2329.7961           1.0866           31.33s\n",
      "        40        2309.2098          -6.2703           31.44s\n",
      "        27        3528.5074         -11.1764            1.78m\n",
      "        28        3597.7115          -1.3869            1.65m\n",
      "        28        3453.7672         -14.0211            1.66m\n",
      "        41        2372.5858          -0.4851           28.22s\n",
      "        41        2342.5676           1.3428           28.20s\n",
      "        41        2325.8419          -4.3874           28.32s\n",
      "        28        3476.5369         -11.7581            1.70m\n",
      "        29        3545.6212         -20.3236            1.57m\n",
      "        42        2299.6285          -5.1209           25.04s\n",
      "        42        2303.5741          -4.3863           25.05s\n",
      "        42        2352.2556          -5.7081           25.14s\n",
      "        29        3398.9988         -15.3745            1.59m\n",
      "        43        2377.7441           0.9533           21.86s\n",
      "        43        2315.6256          -7.4932           21.92s\n",
      "        29        3428.8755         -10.1581            1.62m\n",
      "        43        2321.9223           0.7581           21.95s\n",
      "        30        3501.1701         -10.4813            1.50m\n",
      "        44        2293.3212          -2.2929           18.74s\n",
      "        30        3307.1758          -9.4389            1.52m\n",
      "        44        2311.6356           3.0409           18.75s\n",
      "        44        2280.0673          -6.1227           18.79s\n",
      "        30        3346.4727         -15.1709            1.54m\n",
      "        45        2313.1306          -5.9090           15.58s\n",
      "        31        3356.6436         -15.2303            1.43m\n",
      "        45        2230.2213          -4.8742           15.64s\n",
      "        45        2225.1266          -1.5548           15.65s\n",
      "        31        3373.5882          -8.0937            1.44m\n",
      "        46        2269.5235          20.5630           12.45s\n",
      "        46        2241.1071          -0.2244           12.51s\n",
      "        31        3301.2407         -12.3249            1.46m\n",
      "        46        2255.6787          -4.5442           12.50s\n",
      "        32        3324.1215         -12.5047            1.35m\n",
      "        32        3259.5946          -2.1645            1.36m\n",
      "        47        2233.3316           0.8308            9.35s\n",
      "        47        2219.3825          -4.3985            9.38s\n",
      "        47        2263.9354          -5.0146            9.36s\n",
      "        32        3238.9685         -13.5407            1.38m\n",
      "        33        3300.7304         -16.7769            1.27m\n",
      "        48        2251.1763          -4.2705            6.23s\n",
      "        48        2199.2867          -8.2693            6.25s\n",
      "        48        2259.7655          -6.7564            6.23s\n",
      "        33        3214.5457          -8.9933            1.28m\n",
      "        49        2263.1421          -2.8238            3.12s\n",
      "        49        2191.8011          -5.1421            3.12s\n",
      "        49        2198.3163          -2.0915            3.11s\n",
      "        33        3169.7768         -11.2972            1.30m\n",
      "        34        3200.0576         -18.2763            1.20m\n",
      "        34        3111.7573         -12.3050            1.21m\n",
      "        50        2207.7683         -10.3819            0.00s\n",
      "[CV]  max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False - 2.6min\n",
      "        50        2149.7918          -8.9452            0.00s\n",
      "[CV]  max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False - 2.6min\n",
      "        50        2173.4386           1.3214            0.00s\n",
      "[CV]  max_features=auto, subsample=0.352022639922, learning_rate=0.223350669556, warm_start=False - 2.6min\n",
      "        34        3126.8618         -20.5257            1.22m\n",
      "        35        3207.0322          -6.9511            1.13m\n",
      "        35        3031.2941          -8.7012            1.13m\n",
      "        35        3081.5977         -22.0469            1.15m\n",
      "        36        3102.8380          -8.4901            1.05m\n",
      "        36        3031.8354          -9.0429            1.06m\n",
      "        36        3086.0104         -13.6458            1.07m\n",
      "        37        3069.8787         -11.0639           58.51s\n",
      "        37        2933.6154          -9.5269           59.05s\n",
      "        38        3008.9666         -12.9859           53.97s\n",
      "        37        3003.0163          -8.6163           59.91s\n",
      "        38        2949.9764         -10.1786           54.58s\n",
      "        39        2978.1190         -12.2745           49.49s\n",
      "        38        2979.5453         -10.9690           55.34s\n",
      "        39        2848.0368         -12.4990           50.01s\n",
      "        40        2936.0753         -15.8863           45.03s\n",
      "        39        2840.4258          -8.0947           50.77s\n",
      "        40        2803.7776          -9.8617           45.55s\n",
      "        41        2882.6310         -16.4561           40.55s\n",
      "        40        2831.8158         -14.1565           46.14s\n",
      "        41        2780.7526          -8.1656           40.88s\n",
      "        41        2823.5602          -7.3200           41.44s\n",
      "        42        2789.6318          -8.0803           36.08s\n",
      "        42        2701.0230         -12.1610           36.30s\n",
      "        42        2758.8295          -8.6269           36.79s\n",
      "        43        2816.1094         -13.8372           31.54s\n",
      "        43        2715.6158         -11.6511           31.79s\n",
      "        43        2742.6141         -13.8141           32.12s\n",
      "        44        2730.6837          -6.5050           27.03s\n",
      "        44        2644.0945          -8.5989           27.21s\n",
      "        44        2641.7506           0.7210           27.56s\n",
      "        45        2669.3031         -18.0781           22.52s\n",
      "        45        2634.3085          -9.9246           22.66s\n",
      "        45        2609.6359          -6.7693           22.93s\n",
      "        46        2659.0945         -16.4755           18.04s\n",
      "        46        2586.9106          -5.2517           18.15s\n",
      "        46        2539.3178          -8.7462           18.35s\n",
      "        47        2582.0354          -9.1719           13.53s\n",
      "        47        2527.7047          -4.9107           13.63s\n",
      "        47        2523.7285         -12.0824           13.74s\n",
      "        48        2612.3498         -13.1842            9.03s\n",
      "        48        2500.9915         -13.8082            9.08s\n",
      "        48        2526.7691         -14.2648            9.17s\n",
      "        49        2543.0498          -5.5983            4.52s\n",
      "        49        2431.3355          -8.8112            4.53s\n",
      "        49        2437.3435         -11.4043            4.59s\n",
      "        50        2477.7266         -14.2515            0.00s\n",
      "[CV]  max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False - 3.8min\n",
      "        50        2407.8742          -9.3151            0.00s\n",
      "[CV]  max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False - 3.8min\n",
      "        50        2373.2778         -19.1328            0.00s\n",
      "[CV]  max_features=auto, subsample=0.652295356862, learning_rate=0.534991644241, warm_start=False - 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done   6 out of   6 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       11424.1431        2044.3780            7.08m\n",
      "         2       10101.0188         632.5692            6.87m\n",
      "         3        9521.5385         287.6866            6.53m\n",
      "         4        9010.2908         188.1259            6.33m\n",
      "         5        8708.5143         103.8759            6.08m\n",
      "         6        8370.6366          97.6784            5.90m\n",
      "         7        8122.2043          78.9813            5.71m\n",
      "         8        7957.9672          40.5434            5.50m\n",
      "         9        7742.5850          50.2229            5.33m\n",
      "        10        7588.2933          28.1474            5.17m\n",
      "        11        7484.5944           4.2658            5.03m\n",
      "        12        7317.2439          11.6396            4.89m\n",
      "        13        7172.2904           2.6672            4.73m\n",
      "        14        7079.1946          -0.1389            4.58m\n",
      "        15        6994.2927           7.2261            4.41m\n",
      "        16        6865.6698           0.7620            4.26m\n",
      "        17        6814.9983           1.7694            4.11m\n",
      "        18        6708.3916           0.3420            3.96m\n",
      "        19        6476.3354          -2.6159            3.83m\n",
      "        20        6414.7925           2.1492            3.70m\n",
      "        21        6344.8105          -1.8643            3.57m\n",
      "        22        6284.2783         -12.2068            3.44m\n",
      "        23        6150.0471         -15.6071            3.30m\n",
      "        24        6119.6571           1.3635            3.17m\n",
      "        25        6048.2860          -3.1934            3.03m\n",
      "        26        6009.0176          -8.9173            2.90m\n",
      "        27        5927.3196          -2.3642            2.77m\n",
      "        28        5849.1997         -17.8947            2.64m\n",
      "        29        5748.1015         -13.3066            2.52m\n",
      "        30        5656.0285          -1.4185            2.39m\n",
      "        31        5611.2802         -12.4623            2.27m\n",
      "        32        5562.5751         -10.8284            2.15m\n",
      "        33        5528.6157          -2.9559            2.02m\n",
      "        34        5358.9307         -13.5311            1.90m\n",
      "        35        5322.9522         -32.8201            1.78m\n",
      "        36        5277.8596          -8.0884            1.66m\n",
      "        37        5195.7088          11.8321            1.54m\n",
      "        38        5149.0485         -13.2573            1.42m\n",
      "        39        5069.8775         -11.9771            1.31m\n",
      "        40        4953.5311          -3.4851            1.18m\n",
      "        41        4904.7793          -0.8350            1.07m\n",
      "        42        4858.0732         -13.1231           56.89s\n",
      "        43        4798.3418         -13.1474           49.77s\n",
      "        44        4714.3048         -10.7461           42.68s\n",
      "        45        4650.1522         -16.8687           35.55s\n",
      "        46        4581.0953          -5.1319           28.45s\n",
      "        47        4543.6162          -7.4215           21.33s\n",
      "        48        4546.2738          -7.3250           14.21s\n",
      "        49        4427.2439         -10.5235            7.10s\n",
      "        50        4415.0810         -15.0587            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=12,\n",
       "              min_samples_leaf=10, min_samples_split=10,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=21, subsample=1.0, verbose=2,\n",
       "              warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=2, n_jobs=36,\n",
       "          param_distributions={'max_features': [None, 'auto'], 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff47109a990>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4598cdfd0>, 'warm_start': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "random_search_GBC = RandomizedSearchCV(estimator=model_ivq_GBC,\n",
    "                                                   param_distributions=param_distributions['GBC'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=3, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_GBC.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.534991644241,\n",
       "              loss='deviance', max_depth=3, max_features='auto',\n",
       "              max_leaf_nodes=12, min_samples_leaf=10, min_samples_split=10,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=21, subsample=0.652295356862,\n",
       "              verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_GBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69594435274699362"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_GBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost DT F1 Score:  0.715118653295\n"
     ]
    }
   ],
   "source": [
    "best_GBC = random_search_GBC.best_estimator_\n",
    "y_pred = best_GBC.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 \n",
      "[CV] kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 \n",
      "[CV] kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 \n",
      "[CV] kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 ..\n",
      "[CV] kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 ..\n",
      "[CV] kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][CV]  kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 -  11.8s\n",
      "[LibSVM][CV]  kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 -  12.0s\n",
      "[LibSVM][CV]  kernel=poly, C=0.287845399018, shrinking=False, degree=5, coef0=1 -  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][CV]  kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 -  13.7s\n",
      "[LibSVM][CV]  kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 -  13.8s\n",
      "[LibSVM][CV]  kernel=rbf, C=1.83013321348, shrinking=True, degree=9, coef0=1 -  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done   6 out of   6 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:224: ConvergenceWarning: Solver terminated early (max_iter=20).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=20, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "  verbose=True),\n",
       "          fit_params={}, iid=True, n_iter=2, n_jobs=36,\n",
       "          param_distributions={'kernel': ['rbf', 'poly'], 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff4598d93d0>, 'shrinking': [True, False], 'coef0': [0, 1, 2], 'degree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff459845290>},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 2\n",
    "random_search_SVC = RandomizedSearchCV(estimator=model_ivq_SVC,\n",
    "                                                   param_distributions=param_distributions['SVC'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=3, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_SVC.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.271457203489743"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost DT F1 Score:  0.227904674255\n"
     ]
    }
   ],
   "source": [
    "best_SVC = random_search_SVC.best_estimator_\n",
    "y_pred = best_SVC.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image nComments Quantile (InCQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image nFavs Quantile (InFQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv = sp_expon(loc=0.001, scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rv.rvs(1000), bins=40)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = rv.rvs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

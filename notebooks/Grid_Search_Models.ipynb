{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, LogisticRegressionCV, Lasso, Ridge, RidgeClassifier, SGDClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, precision_recall_fscore_support, f1_score, r2_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint as sp_randint, gamma as sp_gamma, expon as sp_expon, uniform as sp_uniform\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('../data/modeling/SPORTS/feature_data_SPORTS_21205.csv', sep='|')\n",
    "df_targets = pd.read_csv('../data/modeling/SPORTS/target_data_SPORTS_21205.csv', sep='|')\n",
    "\n",
    "df_features = df_features.set_index('owner').set_index(\"id\", append=True)\n",
    "\n",
    "df_targets = df_targets.set_index('owner').set_index(\"id\", append=True)\n",
    "\n",
    "df_targets = df_targets.drop('image_tags', axis=1)\n",
    "\n",
    "target_columns = list(df_targets.columns)\n",
    "target_columns.remove('image_ntags')\n",
    "target_columns\n",
    "\n",
    "df = df_features.join(df_targets, how='inner')\n",
    "\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_quantile(x, limits):\n",
    "    quantile_cats = range(1, len(limits)+1, 1)\n",
    "    for cat, limit in zip(quantile_cats, limits):\n",
    "        if x <= limit:\n",
    "            return cat\n",
    "\n",
    "def create_quantile_target_col(df_train, df_test, target_columns, col_name, n_quantiles=5):\n",
    "    \"\"\"\n",
    "    Create a new column in both DataFrames that bins a target column into categories.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df_train : pandas.DataFrame\n",
    "        The training set data.\n",
    "        \n",
    "    df_test : pandas.DataFrame\n",
    "        The testint set data.\n",
    "    \n",
    "    n_quantiles : int\n",
    "        The number of bins. For 4 bins (0 to 0.25, 0.25 to 0.5, etc...), n_quantiles=4.\n",
    "        \n",
    "    col_name : str\n",
    "    \n",
    "    target_columns : list\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    df : DataFrame\n",
    "    \n",
    "    target_columns : list        \n",
    "    \"\"\"\n",
    "    min_value = df_train[col_name].min()\n",
    "    max_value = df_train[col_name].max()\n",
    "    limits = []\n",
    "    for i in range(1, n_quantiles+1):\n",
    "        limits.append(df_train[col_name].quantile(i/float(n_quantiles)))\n",
    "    \n",
    "    new_col_name = col_name+\"_quantile\"\n",
    "    target_columns.append(new_col_name)\n",
    "    \n",
    "    df_train.loc[:, new_col_name] = df_train[col_name].apply(lambda x: name_quantile(x, limits))\n",
    "    df_test.loc[:, new_col_name] = df_test[col_name].apply(lambda x: name_quantile(x, limits))\n",
    "    return df_train, df_test, target_columns\n",
    "\n",
    "def pop_columns(df, col_names):\n",
    "    for i, name in enumerate(list(col_names)):\n",
    "        if i == 0:\n",
    "            df_dropped_cols = df.pop(name)\n",
    "        else:\n",
    "            df_dropped_cols = pd.concat((df_dropped_cols, df.pop(name)), axis=1)\n",
    "    return df, df_dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_views', 4)\n",
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_ncomments', 4)\n",
    "df_train, df_test, target_columns = create_quantile_target_col(df_train, df_test, target_columns, 'image_nfavs', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = pop_columns(df_train, target_columns)\n",
    "X_test, y_test = pop_columns(df_test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_columns = X_train.columns\n",
    "y_columns = y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_mean_std = StandardScaler()\n",
    "X_train = scaler_mean_std.fit_transform(X_train)\n",
    "X_test = scaler_mean_std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=X_train, columns=X_columns)\n",
    "X_test = pd.DataFrame(data=X_test, columns=X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_is_pro</th>\n",
       "      <th>user_can_buy_pro</th>\n",
       "      <th>user_total_views</th>\n",
       "      <th>image_ncomments</th>\n",
       "      <th>image_nfavs</th>\n",
       "      <th>image_nsets</th>\n",
       "      <th>image_npools</th>\n",
       "      <th>image_views</th>\n",
       "      <th>image_views_quantile</th>\n",
       "      <th>image_ncomments_quantile</th>\n",
       "      <th>image_nfavs_quantile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12385792@N00</th>\n",
       "      <th>11378305226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user_is_pro  user_can_buy_pro  user_total_views  \\\n",
       "owner        id                                                             \n",
       "12385792@N00 11378305226            1                 0              7760   \n",
       "\n",
       "                          image_ncomments  image_nfavs  image_nsets  \\\n",
       "owner        id                                                       \n",
       "12385792@N00 11378305226                0            0            1   \n",
       "\n",
       "                          image_npools  image_views  image_views_quantile  \\\n",
       "owner        id                                                             \n",
       "12385792@N00 11378305226             0            6                     1   \n",
       "\n",
       "                          image_ncomments_quantile  image_nfavs_quantile  \n",
       "owner        id                                                           \n",
       "12385792@N00 11378305226                         1                     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image Views Quantile (IVQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_distributions = {'Logistic': {\"C\": sp_expon(loc=0.001, scale=1),\n",
    "                                    \"fit_intercept\": [True, False],\n",
    "                                    \"intercept_scaling\": sp_randint(1, 5),\n",
    "                                    \"warm_start\": [False, True]\n",
    "                                    },\n",
    "                       'RandomForest': {\"max_depth\": None,\n",
    "                                        \"max_features\": ['auto', None],\n",
    "                                        \"min_samples_split\": sp_randint(1, 201),\n",
    "                                        \"min_samples_leaf\": sp_randint(1, 201),\n",
    "                                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "                                        \"oob_score\": True,\n",
    "                                        \"warm_start\": [False, True] \n",
    "                                        },\n",
    "                       'AdaBoost_DT': {\"learning_rate\": sp_expon(loc=0.001, scale=1.5),\n",
    "                                       \"algorithm\" : ['SAMME.R', 'SAMME']\n",
    "                                       },\n",
    "                       'GBC': {\"learning_rate\": sp_expon(loc=0.001, scale=0.5),\n",
    "                               \"subsample\": sp_uniform(loc=0.2, scale=0.8),\n",
    "                               \"max_features\": [None, 'auto'],\n",
    "                               \"warm_start\": [True, False],\n",
    "                               \"max_depth\": [3, 4, 5],\n",
    "                               },\n",
    "                       'SVC': {\"C\": sp_expon(loc=0.001, scale=2),\n",
    "                               \"kernel\": ['rbf', 'poly'],\n",
    "                               \"degree\": sp_randint(2, 10),\n",
    "                               \"coef0\": [0, 1, 2],\n",
    "                               \"shrinking\": [True, False]\n",
    "                               }\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Models (IVQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, min_samples_split=10, min_samples_leaf=10,\n",
    "      min_weight_fraction_leaf=0.0, max_features=300, random_state=30, max_leaf_nodes=20, class_weight=None,\n",
    "      presort=False)\n",
    "\n",
    "model_ivq_LogitClassifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001,\n",
    "                                               class_weight=None, random_state=25,\n",
    "                                               solver='liblinear', max_iter=1000, multi_class='ovr', verbose=2,\n",
    "                                               n_jobs=36)\n",
    "\n",
    "model_ivq_RandomForest = RandomForestClassifier(n_estimators=1000, min_weight_fraction_leaf=0.0, n_jobs=36,\n",
    "                                                random_state=42, verbose=2, class_weight=None, bootstrap=True)\n",
    "\n",
    "model_ivq_AdaBoost_DT = AdaBoostClassifier(base_estimator=DT, n_estimators=300, random_state=12)\n",
    "\n",
    "model_ivq_GBC = GradientBoostingClassifier(loss='deviance', n_estimators=100,\n",
    "                                           min_samples_split=10, min_samples_leaf=10, min_weight_fraction_leaf=0.0,\n",
    "                                           random_state=21, verbose=0,\n",
    "                                           max_leaf_nodes=12, presort='auto')\n",
    "\n",
    "model_ivq_SVC = SVC(gamma='auto', probability=True,\n",
    "                    tol=0.001, cache_size=1000, class_weight=None, verbose=True, max_iter=-1,\n",
    "                    decision_function_shape='ovr', random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iter_search = 30\n",
    "random_search_LogitClassifier = RandomizedSearchCV(estimator=model_ivq_LogitClassifier,\n",
    "                                                   param_distributions=param_distributions['Logistic'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=5, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_LogitClassifier.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_LogitClassifier.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_LogitClassifier.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_LogitClassifier = random_search_LogitClassifier.best_estimator_\n",
    "y_pred = best_LogitClassifier.predict(X_test)\n",
    "print \"Best Logit Classifier F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter_search = 30\n",
    "random_search_RandomForest = RandomizedSearchCV(estimator=model_ivq_RandomForest,\n",
    "                                                   param_distributions=param_distributions['RandomForest'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=5, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_RandomForest.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_RandomForest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_RandomForest = random_search_RandomForest.best_estimator_\n",
    "y_pred = best_RandomForest.predict(X_test)\n",
    "print \"Best Random Forest Classifier F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost DT Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter_search = 30\n",
    "random_search_AdaBoost_DT = RandomizedSearchCV(estimator=model_ivq_AdaBoost_DT,\n",
    "                                                   param_distributions=param_distributions['AdaBoost_DT'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=5, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_AdaBoost_DT.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_AdaBoost_DT.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_AdaBoost_DT = random_search_AdaBoost_DT.best_estimator_\n",
    "y_pred = best_AdaBoost_DT.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Classifier Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed: 67.9min\n",
      "[Parallel(n_jobs=36)]: Done 200 out of 200 | elapsed: 95.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=12,\n",
       "              min_samples_leaf=10, min_samples_split=10,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=21, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=40, n_jobs=36,\n",
       "          param_distributions={'max_features': [None, 'auto'], 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9cf850c6d0>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9cf851b850>, 'warm_start': [True, False], 'max_depth': [3, 4, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=30, refit=True,\n",
       "          scoring=None, verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 40\n",
    "random_search_GBC = RandomizedSearchCV(estimator=model_ivq_GBC,\n",
    "                                       param_distributions=param_distributions['GBC'],\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       n_jobs=36, cv=5, verbose=1, random_state=30, error_score='raise')\n",
    "random_search_GBC.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73614713510964391"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_GBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost DT F1 Score:  0.745162994441\n"
     ]
    }
   ],
   "source": [
    "best_GBC = random_search_GBC.best_estimator_\n",
    "y_pred = best_GBC.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_params = best_GBC.get_params()\n",
    "new_params['n_estimators'] = 1000\n",
    "new_params['verbose'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model_ivq_GBC = GradientBoostingClassifier(**new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       17394.7394         428.4469          202.13m\n",
      "         2       15607.2196         226.9874          200.65m\n",
      "         3       14446.7362         150.6848          198.27m\n",
      "         4       13650.8799          92.1420          199.15m\n",
      "         5       13094.3819          61.0891          200.64m\n",
      "         6       12598.4263          49.5992          200.76m\n",
      "         7       12259.9390          38.7950          201.24m\n",
      "         8       11946.5230          31.4153          199.45m\n",
      "         9       11697.0205          21.0329          197.50m\n",
      "        10       11451.6005          20.4354          196.28m\n",
      "        11       11239.4997           9.9764          195.64m\n",
      "        12       11049.8318          12.8838          195.18m\n",
      "        13       10847.9050          17.0746          194.48m\n",
      "        14       10662.2817           9.7841          192.52m\n",
      "        15       10520.7765          11.0092          192.04m\n",
      "        16       10292.2345          11.9244          192.71m\n",
      "        17       10210.5201           6.1059          192.22m\n",
      "        18       10079.9487           5.4901          192.67m\n",
      "        19        9892.3285           3.3417          192.42m\n",
      "        20        9769.2917           1.0571          191.00m\n",
      "        21        9719.5784           3.3202          190.23m\n",
      "        22        9594.9468           2.1141          189.72m\n",
      "        23        9474.9218          -2.3215          189.42m\n",
      "        24        9448.6251           0.3550          188.83m\n",
      "        25        9328.5895           1.6112          186.75m\n",
      "        26        9240.8441           0.8340          186.36m\n",
      "        27        9162.2182          -0.2428          185.39m\n",
      "        28        9092.9885          -1.2525          184.05m\n",
      "        29        8947.3163           2.6082          182.75m\n",
      "        30        8898.4063          -2.3533          180.99m\n",
      "        31        8794.2225           1.6727          179.39m\n",
      "        32        8678.9552          -1.2119          177.68m\n",
      "        33        8630.7560          -1.7792          176.22m\n",
      "        34        8581.5069          -1.2370          174.81m\n",
      "        35        8480.4074           2.4543          174.37m\n",
      "        36        8431.5224          -2.9223          173.42m\n",
      "        37        8369.5327           0.2508          172.96m\n",
      "        38        8274.4255           0.2019          171.42m\n",
      "        39        8228.3242           3.7976          170.74m\n",
      "        40        8164.0058           1.0185          169.76m\n",
      "        41        7998.3288          -2.9975          169.67m\n",
      "        42        8013.1263          -1.0754          168.70m\n",
      "        43        7963.0311           0.7657          168.01m\n",
      "        44        7879.7911          -3.6689          167.92m\n",
      "        45        7781.2900          -0.3566          166.77m\n",
      "        46        7727.9512           3.3850          166.52m\n",
      "        47        7629.3250          -2.6979          165.79m\n",
      "        48        7601.4147          -0.7015          165.24m\n",
      "        49        7496.7293           3.6647          164.44m\n",
      "        50        7447.8395           1.5688          163.99m\n",
      "        51        7416.0547          -2.3000          163.70m\n",
      "        52        7276.5124           1.2398          163.70m\n",
      "        53        7273.4202          -0.0968          162.98m\n",
      "        54        7192.4655          -0.8464          162.47m\n",
      "        55        7117.8871          -0.5314          161.83m\n",
      "        56        7111.6306          -1.4871          161.47m\n",
      "        57        7029.1264           0.8873          160.90m\n",
      "        58        6980.9836          -1.0461          160.21m\n",
      "        59        6918.4664          -2.0869          159.94m\n",
      "        60        6841.0988           3.0625          159.42m\n",
      "        61        6785.1616          -1.1144          158.72m\n",
      "        62        6742.5552          -2.0319          158.31m\n",
      "        63        6689.6396          -1.0881          157.65m\n",
      "        64        6656.2534          -0.1430          157.52m\n",
      "        65        6604.2798          -1.1533          156.74m\n",
      "        66        6541.7196          -0.2213          156.24m\n",
      "        67        6493.3534           0.9432          155.62m\n",
      "        68        6461.8119          -0.7121          155.01m\n",
      "        69        6431.5273           0.1639          154.56m\n",
      "        70        6325.4288          -1.2681          154.23m\n",
      "        71        6316.9360          -0.4738          153.85m\n",
      "        72        6264.5580          -0.8503          153.21m\n",
      "        73        6196.6771          -0.5557          152.77m\n",
      "        74        6171.9340           2.3570          152.27m\n",
      "        75        6115.3398          -2.4809          151.63m\n",
      "        76        6095.4296          -1.7868          151.19m\n",
      "        77        5994.5193          -0.6527          150.77m\n",
      "        78        5982.5920           0.5407          150.49m\n",
      "        79        5911.0633           0.6652          149.99m\n",
      "        80        5887.5313          -1.1180          149.62m\n",
      "        81        5816.3624          -0.3075          149.04m\n",
      "        82        5824.6024          -0.7389          148.56m\n",
      "        83        5711.3462          -1.4324          148.06m\n",
      "        84        5734.3164          -0.5040          147.51m\n",
      "        85        5630.9269          -1.2487          146.90m\n",
      "        86        5617.6309          -2.1201          146.51m\n",
      "        87        5574.0320           0.2054          145.83m\n",
      "        88        5540.1737          -0.9430          145.67m\n",
      "        89        5454.7102          -1.0270          145.39m\n",
      "        90        5440.5292          -0.9634          144.86m\n",
      "        91        5421.7215           0.0063          144.71m\n",
      "        92        5414.1495          -2.1587          144.41m\n",
      "        93        5342.1021          -0.7315          144.12m\n",
      "        94        5325.8147          -1.6059          143.69m\n",
      "        95        5269.0303          -1.8961          143.36m\n",
      "        96        5231.5143          -0.9454          143.21m\n",
      "        97        5248.9170          -1.3080          142.99m\n",
      "        98        5149.6266           0.3831          142.65m\n",
      "        99        5137.8744          -0.6984          142.32m\n",
      "       100        5112.8739          -1.5018          142.04m\n",
      "       101        5073.6673          -0.7184          141.64m\n",
      "       102        5026.2009          -0.3770          141.43m\n",
      "       103        5001.3091          -1.8801          140.94m\n",
      "       104        4927.6860          -0.3114          140.76m\n",
      "       105        4904.5674          -1.4617          140.40m\n",
      "       106        4893.5536           0.8865          140.18m\n",
      "       107        4817.8994          -0.5273          140.07m\n",
      "       108        4775.2931          -0.8203          139.76m\n",
      "       109        4761.6448          -0.9020          139.32m\n",
      "       110        4723.1742           0.0426          139.15m\n",
      "       111        4701.9226          -0.8555          138.85m\n",
      "       112        4646.8700          -1.9305          138.48m\n",
      "       113        4634.8322          -1.2362          138.24m\n",
      "       114        4609.0736          -1.6660          138.05m\n",
      "       115        4553.7250          -0.6542          137.91m\n",
      "       116        4520.0597          -0.7521          137.56m\n",
      "       117        4526.0669          -0.6446          137.08m\n",
      "       118        4488.8581          -0.6950          136.84m\n",
      "       119        4462.4740          -1.1799          136.73m\n",
      "       120        4449.1521           0.4548          136.47m\n",
      "       121        4385.7652          -1.2352          136.27m\n",
      "       122        4361.7511          -0.0952          135.99m\n",
      "       123        4321.3243          -0.1240          135.66m\n",
      "       124        4285.2158          -2.1333          135.36m\n",
      "       125        4263.7511          -0.4611          135.18m\n",
      "       126        4244.7782          -0.5940          134.91m\n",
      "       127        4230.9033          -0.7848          134.48m\n",
      "       128        4171.2426          -0.2145          134.20m\n",
      "       129        4132.2737           0.1003          134.04m\n",
      "       130        4114.5053          -0.4931          133.64m\n",
      "       131        4070.0166           0.5187          133.31m\n",
      "       132        4050.9107          -1.2798          133.11m\n",
      "       133        4024.9974          -1.5399          132.91m\n",
      "       134        3983.3702          -1.1892          132.61m\n",
      "       135        3964.0001          -2.1461          132.45m\n",
      "       136        3934.2338          -0.9922          132.22m\n",
      "       137        3933.7758          -1.4859          131.98m\n",
      "       138        3872.0495          -1.5926          131.79m\n",
      "       139        3863.0929          -1.9054          131.50m\n",
      "       140        3849.4053          -0.9161          131.28m\n",
      "       141        3827.5643          -0.8122          131.01m\n",
      "       142        3787.6527          -0.9474          130.89m\n",
      "       143        3739.9002          -1.6012          130.68m\n",
      "       144        3742.0075           0.2843          130.41m\n",
      "       145        3711.9565          -1.3495          130.41m\n",
      "       146        3683.8712          -1.2619          130.17m\n",
      "       147        3680.0116          -1.2680          129.94m\n",
      "       148        3658.7288          -1.7301          129.62m\n",
      "       149        3609.2341          -0.7924          129.41m\n",
      "       150        3578.4218          -0.7014          129.19m\n",
      "       151        3556.5582          -1.2452          128.91m\n",
      "       152        3535.9601          -0.2134          128.70m\n",
      "       153        3509.6604          -0.7135          128.52m\n",
      "       154        3485.1878          -0.8983          128.46m\n",
      "       155        3478.5220          -1.5083          128.27m\n",
      "       156        3429.8122          -0.0116          128.01m\n",
      "       157        3418.1563          -0.3131          127.79m\n",
      "       158        3411.7665          -0.7832          127.57m\n",
      "       159        3378.9444          -1.2014          127.39m\n",
      "       160        3354.4193          -0.0945          127.20m\n",
      "       161        3314.0716          -1.0058          126.90m\n",
      "       162        3300.7497          -0.8322          126.73m\n",
      "       163        3278.6119          -0.2608          126.40m\n",
      "       164        3279.4702          -0.7694          126.26m\n",
      "       165        3231.6501          -0.2124          126.03m\n",
      "       166        3235.8551          -1.1706          125.89m\n",
      "       167        3215.4258          -0.4729          125.62m\n",
      "       168        3198.2309          -0.6616          125.34m\n",
      "       169        3151.5967          -0.6271          125.10m\n",
      "       170        3146.5198          -1.0257          124.84m\n",
      "       171        3132.7539          -0.2145          124.62m\n",
      "       172        3104.9079          -1.3941          124.36m\n",
      "       173        3088.2462          -1.1045          124.13m\n",
      "       174        3042.6499          -0.2655          123.90m\n",
      "       175        3039.3199          -1.3269          123.67m\n",
      "       176        3020.1156          -1.1077          123.40m\n",
      "       177        2986.2635          -0.3729          123.31m\n",
      "       178        2951.2809          -0.9928          123.04m\n",
      "       179        2956.0068          -0.5632          122.87m\n",
      "       180        2918.9379          -0.7505          122.74m\n",
      "       181        2915.7561          -0.9037          122.48m\n",
      "       182        2882.8686          -0.8234          122.24m\n",
      "       183        2870.8646          -0.5402          122.02m\n",
      "       184        2865.4287          -0.2118          121.87m\n",
      "       185        2842.1276          -0.5685          121.64m\n",
      "       186        2812.0798          -0.6051          121.41m\n",
      "       187        2805.9999          -0.6550          121.25m\n",
      "       188        2788.6193          -0.7967          121.10m\n",
      "       189        2764.2110          -1.3858          120.85m\n",
      "       190        2743.2404          -0.7776          120.64m\n",
      "       191        2717.8197          -0.5819          120.56m\n",
      "       192        2708.6383           0.1223          120.37m\n",
      "       193        2687.1401          -0.9710          120.22m\n",
      "       194        2658.9556          -0.5284          119.91m\n",
      "       195        2661.9776          -1.0336          119.63m\n",
      "       196        2640.8956          -0.5717          119.43m\n",
      "       197        2622.1165          -0.6605          119.25m\n",
      "       198        2602.0448          -0.3916          119.02m\n",
      "       199        2562.2640          -1.0185          118.83m\n",
      "       200        2574.2441          -0.6244          118.50m\n",
      "       201        2543.5100          -0.9585          118.28m\n",
      "       202        2521.8169          -1.1593          118.13m\n",
      "       203        2514.6922          -0.8426          118.00m\n",
      "       204        2512.9121          -1.3049          117.75m\n",
      "       205        2486.3374          -0.7926          117.52m\n",
      "       206        2466.6082          -0.5644          117.36m\n",
      "       207        2457.3159          -0.5848          117.11m\n",
      "       208        2434.8692          -0.8360          116.87m\n",
      "       209        2434.8037          -0.2940          116.66m\n",
      "       210        2419.2853          -0.7098          116.49m\n",
      "       211        2399.9051          -0.2802          116.33m\n",
      "       212        2391.0867          -0.6803          116.06m\n",
      "       213        2364.9050          -0.4770          115.95m\n",
      "       214        2348.0167          -1.1813          115.81m\n",
      "       215        2338.0689           0.0381          115.63m\n",
      "       216        2329.2208          -0.1395          115.47m\n",
      "       217        2308.7143           0.3381          115.24m\n",
      "       218        2292.7277          -0.6414          115.00m\n",
      "       219        2275.1996          -0.8437          114.74m\n",
      "       220        2259.5927          -1.5275          114.51m\n",
      "       221        2244.3383          -0.5660          114.33m\n",
      "       222        2243.3473           0.0167          114.17m\n",
      "       223        2231.1850          -0.9496          113.98m\n",
      "       224        2215.8261          -0.8153          113.79m\n",
      "       225        2188.2934          -0.4031          113.68m\n",
      "       226        2183.4610           0.4180          113.52m\n",
      "       227        2163.8859          -0.8607          113.30m\n",
      "       228        2131.5966          -0.6999          113.11m\n",
      "       229        2142.9486          -0.4037          112.95m\n",
      "       230        2119.4920          -0.1002          112.76m\n",
      "       231        2108.7428          -0.2936          112.51m\n",
      "       232        2091.9256          -0.5169          112.24m\n",
      "       233        2079.9192          -0.3883          112.07m\n",
      "       234        2079.5293          -0.7621          111.83m\n",
      "       235        2056.3922          -0.6328          111.69m\n",
      "       236        2043.1335          -1.0774          111.58m\n",
      "       237        2025.2757          -0.4693          111.34m\n",
      "       238        2016.7356          -0.8419          111.15m\n",
      "       239        2014.8819          -0.1912          110.97m\n",
      "       240        1993.4833          -0.1375          110.76m\n",
      "       241        1983.0952          -0.5810          110.61m\n",
      "       242        1971.2186          -0.7301          110.44m\n",
      "       243        1946.8379           0.1110          110.30m\n",
      "       244        1937.1814          -0.8311          110.12m\n",
      "       245        1917.4248          -0.7103          109.91m\n",
      "       246        1916.9600          -0.6053          109.71m\n",
      "       247        1901.1058          -0.3512          109.48m\n",
      "       248        1900.0663          -0.2405          109.27m\n",
      "       249        1874.7905          -0.6887          109.06m\n",
      "       250        1874.9982          -0.7330          108.94m\n",
      "       251        1857.6003          -0.2399          108.68m\n",
      "       252        1849.5104          -0.4969          108.51m\n",
      "       253        1829.1723          -0.2068          108.32m\n",
      "       254        1823.0482          -0.6358          108.24m\n",
      "       255        1812.8936          -0.7521          108.05m\n",
      "       256        1797.1472          -0.3932          107.87m\n",
      "       257        1794.1376          -0.2214          107.72m\n",
      "       258        1776.8965           0.5564          107.58m\n",
      "       259        1761.1785          -0.3943          107.35m\n",
      "       260        1758.7917          -0.4440          107.19m\n",
      "       261        1743.5856          -0.3913          106.94m\n",
      "       262        1723.8304          -0.9945          106.79m\n",
      "       263        1719.9781          -0.5885          106.57m\n",
      "       264        1709.2011          -0.5185          106.39m\n",
      "       265        1705.8309          -0.6230          106.31m\n",
      "       266        1681.1281          -0.6998          106.15m\n",
      "       267        1687.3055          -0.8192          106.01m\n",
      "       268        1673.0880          -0.1113          105.80m\n",
      "       269        1654.5244          -0.8218          105.62m\n",
      "       270        1655.2434          -0.2914          105.50m\n",
      "       271        1644.5984          -0.6029          105.32m\n",
      "       272        1637.5046          -0.5123          105.13m\n",
      "       273        1622.8741          -0.8804          104.99m\n",
      "       274        1608.9916          -0.6439          104.82m\n",
      "       275        1600.6500          -0.3777          104.61m\n",
      "       276        1592.6053          -0.4573          104.49m\n",
      "       277        1573.4741          -0.5633          104.32m\n",
      "       278        1575.0386          -0.2110          104.13m\n",
      "       279        1568.7168          -0.6404          103.98m\n",
      "       280        1554.6361          -0.3765          103.76m\n",
      "       281        1543.0876          -0.4947          103.62m\n",
      "       282        1532.6540          -0.3344          103.43m\n",
      "       283        1525.1035          -0.3512          103.28m\n",
      "       284        1519.8376          -0.6589          103.11m\n",
      "       285        1501.4964           0.1981          102.93m\n",
      "       286        1496.0836          -0.1824          102.75m\n",
      "       287        1490.3627          -0.5763          102.57m\n",
      "       288        1474.7561          -0.3351          102.44m\n",
      "       289        1467.8675          -0.5868          102.37m\n",
      "       290        1454.7441          -0.8676          102.21m\n",
      "       291        1456.7556          -0.7139          101.98m\n",
      "       292        1445.8053          -0.4357          101.83m\n",
      "       293        1433.9290          -0.2450          101.66m\n",
      "       294        1429.2176          -0.2756          101.54m\n",
      "       295        1407.0687          -0.2332          101.37m\n",
      "       296        1409.2509          -0.6360          101.25m\n",
      "       297        1393.7494          -0.2442          101.11m\n",
      "       298        1388.5868          -0.6027          100.96m\n",
      "       299        1377.0230          -0.1599          100.70m\n",
      "       300        1375.0314          -0.2626          100.54m\n",
      "       301        1365.0566          -0.5565          100.34m\n",
      "       302        1362.4997          -0.2953          100.13m\n",
      "       303        1356.4985          -0.0543           99.94m\n",
      "       304        1340.1007          -0.0324           99.77m\n",
      "       305        1330.4182          -0.5766           99.62m\n",
      "       306        1320.6857           0.1635           99.45m\n",
      "       307        1307.5795          -0.4362           99.31m\n",
      "       308        1310.2117          -0.5423           99.17m\n",
      "       309        1295.2878          -0.2210           99.00m\n",
      "       310        1293.1466          -0.5457           98.83m\n",
      "       311        1286.1349          -0.5325           98.65m\n",
      "       312        1277.9273          -0.3840           98.43m\n",
      "       313        1269.8189          -0.1674           98.27m\n",
      "       314        1251.1709          -0.3997           98.11m\n",
      "       315        1254.5581          -0.2916           98.00m\n",
      "       316        1253.6233          -0.2740           97.81m\n",
      "       317        1236.0533          -0.4669           97.66m\n",
      "       318        1230.0617          -0.5979           97.49m\n",
      "       319        1230.0909           0.0913           97.33m\n",
      "       320        1218.4368          -0.2949           97.19m\n",
      "       321        1214.5640          -0.1579           97.04m\n",
      "       322        1208.7292          -0.5719           96.86m\n",
      "       323        1200.6182          -0.6102           96.68m\n",
      "       324        1187.6102          -0.5170           96.49m\n",
      "       325        1187.8488          -0.3591           96.33m\n",
      "       326        1173.6284          -0.5912           96.14m\n",
      "       327        1168.3419          -0.1867           96.00m\n",
      "       328        1162.4568          -0.3384           95.85m\n",
      "       329        1152.0658           0.3615           95.70m\n",
      "       330        1146.9297          -0.3687           95.50m\n",
      "       331        1146.9149          -0.3538           95.35m\n",
      "       332        1137.3963          -0.3936           95.18m\n",
      "       333        1127.1055          -0.3491           95.06m\n",
      "       334        1117.4043          -0.4900           94.89m\n",
      "       335        1120.1724          -0.0777           94.70m\n",
      "       336        1104.0066          -0.2523           94.54m\n",
      "       337        1101.7866          -0.3884           94.38m\n",
      "       338        1087.3643          -0.6244           94.27m\n",
      "       339        1089.4010          -0.4949           94.15m\n",
      "       340        1080.1635          -0.3791           93.98m\n",
      "       341        1074.6560          -0.5305           93.80m\n",
      "       342        1070.8272          -0.2042           93.62m\n",
      "       343        1067.3670          -0.2221           93.46m\n",
      "       344        1057.5182          -0.1170           93.31m\n",
      "       345        1047.1646          -0.4389           93.17m\n",
      "       346        1044.4793          -0.2037           93.02m\n",
      "       347        1040.0253          -0.5476           92.89m\n",
      "       348        1029.8820          -0.3115           92.73m\n",
      "       349        1027.6259          -0.5143           92.54m\n",
      "       350        1018.9981          -0.3583           92.42m\n",
      "       351        1010.9356          -0.2540           92.27m\n",
      "       352        1011.6892          -0.2880           92.10m\n",
      "       353        1001.3497          -0.0702           91.96m\n",
      "       354        1001.3082          -0.0921           91.82m\n",
      "       355         991.3885          -0.2185           91.69m\n",
      "       356         977.6300          -0.3267           91.53m\n",
      "       357         977.1983          -0.2415           91.37m\n",
      "       358         972.1581          -0.3208           91.18m\n",
      "       359         967.2931          -0.4514           91.05m\n",
      "       360         960.6913          -0.2677           90.87m\n",
      "       361         956.1845          -0.1082           90.74m\n",
      "       362         949.9549          -0.1545           90.59m\n",
      "       363         943.5945          -0.2263           90.43m\n",
      "       364         936.9527          -0.2606           90.25m\n",
      "       365         931.0390           0.0171           90.08m\n",
      "       366         921.8569          -0.1997           89.95m\n",
      "       367         916.5744          -0.2157           89.79m\n",
      "       368         915.4787          -0.1796           89.63m\n",
      "       369         909.6651          -0.4346           89.49m\n",
      "       370         906.9697          -0.2513           89.37m\n",
      "       371         900.1316          -0.3065           89.24m\n",
      "       372         896.5078          -0.2245           89.05m\n",
      "       373         888.0988          -0.2890           88.91m\n",
      "       374         887.2196          -0.2313           88.76m\n",
      "       375         883.0119          -0.4590           88.60m\n",
      "       376         876.4144          -0.0745           88.42m\n",
      "       377         869.9248          -0.3224           88.26m\n",
      "       378         869.6649          -0.2346           88.12m\n",
      "       379         862.0089          -0.1849           87.98m\n",
      "       380         858.8847          -0.2434           87.79m\n",
      "       381         850.0726          -0.5177           87.64m\n",
      "       382         851.4108          -0.3715           87.47m\n",
      "       383         842.4161          -0.0174           87.29m\n",
      "       384         835.9436          -0.1312           87.13m\n",
      "       385         831.6640          -0.3700           86.96m\n",
      "       386         825.3002          -0.2804           86.81m\n",
      "       387         821.9451          -0.3049           86.66m\n",
      "       388         817.8047          -0.3762           86.53m\n",
      "       389         809.6230          -0.1290           86.36m\n",
      "       390         809.4326          -0.2727           86.22m\n",
      "       391         801.3648          -0.3315           86.04m\n",
      "       392         798.1472          -0.2950           85.88m\n",
      "       393         790.3893          -0.2742           85.74m\n",
      "       394         788.1742          -0.5288           85.59m\n",
      "       395         787.8189          -0.1955           85.47m\n",
      "       396         782.7352          -0.2958           85.29m\n",
      "       397         780.3220          -0.3169           85.13m\n",
      "       398         775.0620          -0.2050           84.97m\n",
      "       399         771.2684          -0.5835           84.84m\n",
      "       400         768.8552          -0.1798           84.69m\n",
      "       401         763.6033          -0.1172           84.54m\n",
      "       402         757.4799          -0.2143           84.44m\n",
      "       403         750.2838          -0.1467           84.29m\n",
      "       404         746.6921          -0.2705           84.13m\n",
      "       405         738.9283          -0.4198           83.98m\n",
      "       406         741.8822          -0.2459           83.85m\n",
      "       407         733.6881          -0.1748           83.70m\n",
      "       408         729.9715          -0.2406           83.54m\n",
      "       409         728.7229          -0.1789           83.37m\n",
      "       410         721.9624          -0.1196           83.24m\n",
      "       411         720.3882          -0.2972           83.06m\n",
      "       412         717.4083          -0.2006           82.89m\n",
      "       413         710.9051          -0.3424           82.72m\n",
      "       414         706.0069          -0.2238           82.58m\n",
      "       415         704.5211          -0.3976           82.45m\n",
      "       416         700.5016          -0.1616           82.29m\n",
      "       417         696.5280          -0.0762           82.12m\n",
      "       418         694.5886          -0.3638           81.98m\n",
      "       419         689.2794          -0.2075           81.83m\n",
      "       420         683.9490          -0.4057           81.68m\n",
      "       421         684.3751          -0.2130           81.53m\n",
      "       422         679.6614          -0.3305           81.38m\n",
      "       423         671.8347          -0.3074           81.25m\n",
      "       424         670.9025          -0.1700           81.09m\n",
      "       425         664.5246          -0.1762           80.95m\n",
      "       426         661.9516          -0.1190           80.79m\n",
      "       427         656.7540          -0.2340           80.65m\n",
      "       428         650.5115          -0.1577           80.48m\n",
      "       429         649.2873          -0.2365           80.32m\n",
      "       430         647.4028          -0.2332           80.16m\n",
      "       431         641.5927          -0.1674           80.01m\n",
      "       432         640.5809          -0.2202           79.87m\n",
      "       433         635.8557          -0.1660           79.71m\n",
      "       434         632.8747          -0.0914           79.54m\n",
      "       435         628.8740          -0.2174           79.38m\n",
      "       436         626.8109          -0.3737           79.26m\n",
      "       437         623.5335          -0.2741           79.08m\n",
      "       438         618.6281          -0.2701           78.93m\n",
      "       439         617.1510          -0.1360           78.76m\n",
      "       440         612.3574          -0.0283           78.62m\n",
      "       441         609.3791          -0.3611           78.51m\n",
      "       442         606.2355          -0.2170           78.36m\n",
      "       443         599.9098          -0.2851           78.19m\n",
      "       444         597.9564          -0.2386           78.03m\n",
      "       445         594.7483          -0.2775           77.90m\n",
      "       446         592.2116          -0.2767           77.74m\n",
      "       447         587.2545          -0.1789           77.59m\n",
      "       448         583.7933          -0.1394           77.44m\n",
      "       449         582.7262          -0.1005           77.32m\n",
      "       450         580.3814          -0.1716           77.16m\n",
      "       451         572.6785          -0.1821           77.01m\n",
      "       452         572.0947          -0.2391           76.88m\n",
      "       453         570.1580          -0.4291           76.75m\n",
      "       454         564.6760          -0.1248           76.57m\n",
      "       455         567.4829          -0.1262           76.43m\n",
      "       456         562.5527          -0.0308           76.26m\n",
      "       457         558.1822          -0.2450           76.12m\n",
      "       458         556.4942          -0.1913           75.97m\n",
      "       459         550.3346          -0.1836           75.80m\n",
      "       460         547.3271          -0.0977           75.65m\n",
      "       461         547.7722          -0.1961           75.53m\n",
      "       462         545.2777          -0.4114           75.38m\n",
      "       463         542.2713           0.0166           75.21m\n",
      "       464         538.3717          -0.4055           75.04m\n",
      "       465         535.7015          -0.1252           74.90m\n",
      "       466         533.0337          -0.1854           74.76m\n",
      "       467         529.8294          -0.1257           74.63m\n",
      "       468         525.2971          -0.1372           74.47m\n",
      "       469         521.1312          -0.6802           74.33m\n",
      "       470         519.0546          -0.1272           74.19m\n",
      "       471         514.6632          -0.0351           74.04m\n",
      "       472         511.0474          -0.1800           73.92m\n",
      "       473         508.3855          -0.1222           73.77m\n",
      "       474         507.0665          -0.2598           73.60m\n",
      "       475         504.4711          -0.1691           73.46m\n",
      "       476         503.5749          -0.1673           73.29m\n",
      "       477         501.1096          -0.1022           73.15m\n",
      "       478         496.3956          -0.1529           73.01m\n",
      "       479         494.0909          -0.2760           72.85m\n",
      "       480         491.4529          -0.1284           72.74m\n",
      "       481         486.2304          -0.1452           72.58m\n",
      "       482         488.4439          -0.1315           72.42m\n",
      "       483         478.9560          -0.1635           72.28m\n",
      "       484         478.8072          -0.2880           72.12m\n",
      "       485         476.4148          -0.1188           72.00m\n",
      "       486         471.8137          -0.2223           71.85m\n",
      "       487         470.5746          -0.1527           71.68m\n",
      "       488         469.1265          -0.0613           71.53m\n",
      "       489         464.8330          -0.2759           71.36m\n",
      "       490         465.1413          -0.1050           71.22m\n",
      "       491         460.9658          -0.1609           71.09m\n",
      "       492         459.0208          -0.4269           70.97m\n",
      "       493         458.3473          -0.2078           70.82m\n",
      "       494         454.4965          -0.0927           70.68m\n",
      "       495         452.3611          -0.1328           70.52m\n",
      "       496         449.4673          -0.1017           70.36m\n",
      "       497         446.9046          -0.2445           70.24m\n",
      "       498         446.8591          -0.5210           70.08m\n",
      "       499         444.6203          -0.0660           69.92m\n",
      "       500         442.6470          -0.1540           69.76m\n",
      "       501         437.3954          -0.1783           69.61m\n",
      "       502         433.8420          -0.0677           69.47m\n",
      "       503         431.9306          -0.4134           69.32m\n",
      "       504         430.8546          -0.1544           69.20m\n",
      "       505         429.0350          -0.2049           69.06m\n",
      "       506         427.0328          -0.2257           68.90m\n",
      "       507         422.8323          -0.1791           68.77m\n",
      "       508         419.6310          -0.5014           68.63m\n",
      "       509         419.7953          -0.0598           68.48m\n",
      "       510         417.1461          -0.1835           68.33m\n",
      "       511         415.0969          -0.1335           68.20m\n",
      "       512         413.6980          -0.0333           68.05m\n",
      "       513         410.3358          -0.4553           67.91m\n",
      "       514         409.9006          -0.1248           67.76m\n",
      "       515         405.9092          -0.1874           67.63m\n",
      "       516         404.7165          -0.1297           67.50m\n",
      "       517         401.2465          -0.2894           67.35m\n",
      "       518         399.2623          -0.0831           67.21m\n",
      "       519         396.5708          -0.1513           67.06m\n",
      "       520         395.2897          -0.1661           66.94m\n",
      "       521         391.7713          -0.0265           66.79m\n",
      "       522         389.0123          -0.0828           66.65m\n",
      "       523         388.7497          -0.0968           66.50m\n",
      "       524         386.6621          -0.0842           66.35m\n",
      "       525         385.0016          -0.1414           66.22m\n",
      "       526         383.2256          -0.2013           66.08m\n",
      "       527         381.0454          -0.1644           65.93m\n",
      "       528         379.3550          -0.0880           65.79m\n",
      "       529         377.6598          -0.1340           65.65m\n",
      "       530         374.0801          -0.2217           65.51m\n",
      "       531         372.5292          -0.0666           65.38m\n",
      "       532         371.0194          -0.0432           65.22m\n",
      "       533         368.1786          -0.0905           65.07m\n",
      "       534         366.2513          -0.4841           64.93m\n",
      "       535         364.0465          -0.4616           64.78m\n",
      "       536         361.6972          -0.2002           64.65m\n",
      "       537         360.2259           0.0846           64.51m\n",
      "       538         357.5427          -0.0718           64.38m\n",
      "       539         355.8344          -0.1244           64.25m\n",
      "       540         352.8857          -0.6088           64.10m\n",
      "       541         351.2491          -0.1556           63.96m\n",
      "       542         347.9266          -0.4368           63.82m\n",
      "       543         349.9800          -0.1697           63.66m\n",
      "       544         345.2679          -0.0281           63.51m\n",
      "       545         343.0614          -0.1726           63.40m\n",
      "       546         341.9186          -0.1445           63.26m\n",
      "       547         340.8428          -0.1901           63.11m\n",
      "       548         337.9880          -0.4600           62.97m\n",
      "       549         337.6281          -0.1008           62.81m\n",
      "       550         336.0605          -0.0330           62.65m\n",
      "       551         333.8715          -0.1225           62.52m\n",
      "       552         332.3464          -0.1570           62.37m\n",
      "       553         329.5486          -0.4601           62.25m\n",
      "       554         328.7518          -0.1703           62.10m\n",
      "       555         329.3083          -0.5605           61.97m\n",
      "       556         325.9101          -0.1147           61.84m\n",
      "       557         322.9079          -0.1023           61.69m\n",
      "       558         323.3787          -0.0826           61.56m\n",
      "       559         319.3902          -0.5319           61.42m\n",
      "       560         320.7901          -0.0536           61.28m\n",
      "       561         316.8243          -0.0488           61.13m\n",
      "       562         315.1455          -0.0853           60.98m\n",
      "       563         312.9994          -0.0200           60.82m\n",
      "       564         311.5640          -0.4285           60.69m\n",
      "       565         308.9514          -0.0252           60.54m\n",
      "       566         308.0795          -0.0323           60.39m\n",
      "       567         306.9207          -0.4785           60.25m\n",
      "       568         306.3873          -0.1095           60.12m\n",
      "       569         301.9019          -0.4534           59.97m\n",
      "       570         300.7922          -0.1079           59.84m\n",
      "       571         300.9717          -0.0725           59.69m\n",
      "       572         298.4957          -0.4021           59.57m\n",
      "       573         295.3299          -0.3799           59.42m\n",
      "       574         295.0390          -0.0709           59.29m\n",
      "       575         293.4778          -0.0751           59.17m\n",
      "       576         290.1221          -0.3695           59.02m\n",
      "       577         290.0870          -0.5127           58.89m\n",
      "       578         289.1753          -0.1027           58.77m\n",
      "       579         286.3490          -0.4165           58.64m\n",
      "       580         285.1025          -0.1168           58.49m\n",
      "       581         283.9347          -0.0955           58.34m\n",
      "       582         283.5922          -0.0741           58.19m\n",
      "       583         282.1919          -0.1328           58.05m\n",
      "       584         280.9861          -0.0758           57.89m\n",
      "       585         280.0966          -0.4710           57.74m\n",
      "       586         277.9908          -0.1345           57.61m\n",
      "       587         275.1952          -0.1183           57.46m\n",
      "       588         275.8522          -0.0032           57.31m\n",
      "       589         274.8719          -0.0435           57.16m\n",
      "       590         272.1133          -0.0441           57.03m\n",
      "       591         272.2433          -0.0364           56.88m\n",
      "       592         270.1311          -0.0712           56.73m\n",
      "       593         266.7409          -0.0876           56.59m\n",
      "       594         267.8139          -0.0583           56.45m\n",
      "       595         266.1155          -0.0919           56.31m\n",
      "       596         261.9493          -0.4952           56.19m\n",
      "       597         262.7816          -0.4715           56.06m\n",
      "       598         260.8515          -0.1157           55.92m\n",
      "       599         261.5213          -0.1565           55.79m\n",
      "       600         258.0463          -0.3745           55.65m\n",
      "       601         256.6723          -0.4046           55.52m\n",
      "       602         257.0162          -0.5074           55.39m\n",
      "       603         257.4115          -0.1174           55.25m\n",
      "       604         254.4463          -0.0616           55.11m\n",
      "       605         253.5488          -0.0991           54.97m\n",
      "       606         252.1849          -0.0325           54.83m\n",
      "       607         249.8919          -0.0850           54.69m\n",
      "       608         247.3782          -0.3932           54.56m\n",
      "       609         246.5893          -0.0780           54.43m\n",
      "       610         246.2558          -0.0745           54.28m\n",
      "       611         244.4930          -0.5012           54.15m\n",
      "       612         243.3752          -0.0765           54.01m\n",
      "       613         243.0634          -0.0527           53.88m\n",
      "       614         241.4479          -0.0443           53.75m\n",
      "       615         241.3862          -0.0253           53.60m\n",
      "       616         237.4390          -0.5118           53.46m\n",
      "       617         236.4381          -0.0097           53.31m\n",
      "       618         237.9946          -0.0510           53.17m\n",
      "       619         233.9390          -0.4430           53.02m\n",
      "       620         232.9461          -0.0671           52.89m\n",
      "       621         232.8353          -0.0705           52.75m\n",
      "       622         231.1951          -0.0641           52.60m\n",
      "       623         230.5710          -0.0412           52.45m\n",
      "       624         228.2784          -0.0055           52.32m\n",
      "       625         226.6579          -0.4703           52.18m\n",
      "       626         225.8020          -0.4494           52.06m\n",
      "       627         224.4990          -0.1078           51.92m\n",
      "       628         223.8539          -0.0405           51.79m\n",
      "       629         223.0827          -0.0205           51.65m\n",
      "       630         221.9610          -0.0989           51.51m\n",
      "       631         219.0916          -0.0470           51.37m\n",
      "       632         219.6921          -0.0581           51.23m\n",
      "       633         218.4898          -0.1001           51.08m\n",
      "       634         218.0319           0.0101           50.93m\n",
      "       635         215.8341          -0.0420           50.78m\n",
      "       636         213.7517          -0.0742           50.64m\n",
      "       637         214.4823          -0.0894           50.49m\n",
      "       638         212.5839          -0.0670           50.34m\n",
      "       639         211.8717          -0.0403           50.19m\n",
      "       640         210.9341          -0.0731           50.05m\n",
      "       641         208.3165          -0.1022           49.92m\n",
      "       642         206.8615          -0.4805           49.77m\n",
      "       643         208.2269          -0.0477           49.64m\n",
      "       644         205.6715          -0.4492           49.50m\n",
      "       645         205.5842          -0.0824           49.36m\n",
      "       646         202.9239          -0.1005           49.21m\n",
      "       647         203.6122          -0.0091           49.07m\n",
      "       648         203.0078          -0.1199           48.92m\n",
      "       649         202.1941          -0.0475           48.77m\n",
      "       650         200.8169          -0.0336           48.64m\n",
      "       651         200.6154          -0.0550           48.50m\n",
      "       652         197.1516          -0.5097           48.36m\n",
      "       653         197.7584          -0.0723           48.24m\n",
      "       654         196.8857          -0.0520           48.09m\n",
      "       655         195.4926          -0.0625           47.95m\n",
      "       656         194.0964          -0.0843           47.81m\n",
      "       657         193.5188          -0.1289           47.68m\n",
      "       658         191.3021          -0.4550           47.55m\n",
      "       659         190.1083          -0.0595           47.41m\n",
      "       660         190.6036          -0.0410           47.27m\n",
      "       661         189.7157          -0.0347           47.13m\n",
      "       662         187.9974          -0.0733           47.00m\n",
      "       663         187.9150          -0.0767           46.86m\n",
      "       664         186.8571          -0.0220           46.72m\n",
      "       665         185.3484          -0.0413           46.58m\n",
      "       666         183.9538          -0.0681           46.44m\n",
      "       667         182.7794          -0.0177           46.31m\n",
      "       668         183.1991          -0.0238           46.17m\n",
      "       669         179.8101          -0.0498           46.04m\n",
      "       670         178.8469          -0.4811           45.90m\n",
      "       671         179.6752          -0.0427           45.76m\n",
      "       672         179.2698          -0.0583           45.63m\n",
      "       673         177.7680          -0.0466           45.49m\n",
      "       674         175.9112          -0.4542           45.36m\n",
      "       675         175.2446          -0.4117           45.22m\n",
      "       676         174.2499          -0.4405           45.09m\n",
      "       677         172.5212          -0.4710           44.95m\n",
      "       678         172.3956          -0.4594           44.81m\n",
      "       679         172.4654          -0.0437           44.66m\n",
      "       680         170.9395          -0.0614           44.52m\n",
      "       681         169.7921          -0.0914           44.39m\n",
      "       682         167.4311          -0.4512           44.25m\n",
      "       683         168.9715          -0.0651           44.11m\n",
      "       684         167.7670          -0.0512           43.98m\n",
      "       685         165.4235          -0.5111           43.84m\n",
      "       686         165.6164          -0.0530           43.70m\n",
      "       687         165.2109          -0.0671           43.56m\n",
      "       688         163.8780          -0.0471           43.41m\n",
      "       689         163.5331          -0.0075           43.28m\n",
      "       690         161.5390           0.0083           43.13m\n",
      "       691         160.1919          -0.0338           43.00m\n",
      "       692         158.8287          -0.4569           42.87m\n",
      "       693         160.0159          -0.0206           42.72m\n",
      "       694         158.9854          -0.0542           42.58m\n",
      "       695         157.7611          -0.0350           42.43m\n",
      "       696         157.1205          -0.0427           42.28m\n",
      "       697         155.8691          -0.3837           42.14m\n",
      "       698         154.7730           0.0507           42.00m\n",
      "       699         154.4880          -0.0305           41.86m\n",
      "       700         153.5987          -0.0764           41.71m\n",
      "       701         153.8170          -0.0416           41.57m\n",
      "       702         151.2156          -0.4999           41.43m\n",
      "       703         151.7815          -0.0439           41.31m\n",
      "       704         151.2469          -0.0454           41.17m\n",
      "       705         149.6613          -0.0494           41.02m\n",
      "       706         149.0617          -0.0418           40.87m\n",
      "       707         148.3815          -0.0372           40.73m\n",
      "       708         147.8183          -0.0130           40.59m\n",
      "       709         146.9930          -0.0335           40.45m\n",
      "       710         146.3030          -0.0361           40.30m\n",
      "       711         144.0083          -0.4025           40.17m\n",
      "       712         144.2524          -0.0413           40.03m\n",
      "       713         143.7632          -0.0665           39.90m\n",
      "       714         143.6923          -0.0012           39.75m\n",
      "       715         143.2522          -0.0438           39.61m\n",
      "       716         141.5567          -0.0459           39.47m\n",
      "       717         140.4746          -0.0463           39.33m\n",
      "       718         140.3643          -0.0307           39.18m\n",
      "       719         139.5285          -0.0291           39.04m\n",
      "       720         138.4947          -0.0464           38.90m\n",
      "       721         138.3745          -0.0481           38.77m\n",
      "       722         137.2616          -0.0722           38.64m\n",
      "       723         136.8259          -0.0350           38.49m\n",
      "       724         136.4868          -0.0166           38.35m\n",
      "       725         135.2481          -0.0554           38.21m\n",
      "       726         134.3074          -0.4196           38.08m\n",
      "       727         133.6565          -0.0423           37.95m\n",
      "       728         133.0351          -0.0239           37.81m\n",
      "       729         132.5031          -0.0094           37.67m\n",
      "       730         132.5020          -0.0420           37.52m\n",
      "       731         130.9649          -0.0156           37.38m\n",
      "       732         130.1761          -0.0402           37.24m\n",
      "       733         129.2756          -0.0421           37.10m\n",
      "       734         129.0665          -0.0736           36.96m\n",
      "       735         127.6925          -0.4570           36.82m\n",
      "       736         127.5562          -0.0582           36.68m\n",
      "       737         126.9997          -0.0423           36.53m\n",
      "       738         126.2305          -0.4425           36.40m\n",
      "       739         126.2742          -0.0311           36.26m\n",
      "       740         125.7589          -0.0153           36.12m\n",
      "       741         124.5674          -0.0480           35.98m\n",
      "       742         124.1132          -0.0492           35.84m\n",
      "       743         122.7110          -0.4451           35.71m\n",
      "       744         123.4878          -0.0513           35.57m\n",
      "       745         122.0638          -0.4520           35.43m\n",
      "       746         121.9007          -0.0312           35.29m\n",
      "       747         121.6283          -0.0178           35.15m\n",
      "       748         120.6732          -0.0360           35.01m\n",
      "       749         120.0651          -0.0366           34.88m\n",
      "       750         118.0702          -0.4397           34.74m\n",
      "       751         118.2649          -0.0176           34.60m\n",
      "       752         118.2189          -0.0179           34.46m\n",
      "       753         117.5867          -0.0252           34.31m\n",
      "       754         116.9987          -0.0185           34.17m\n",
      "       755         116.3641          -0.0180           34.04m\n",
      "       756         115.5582          -0.0207           33.89m\n",
      "       757         114.7726           0.0125           33.75m\n",
      "       758         113.7402          -0.0485           33.61m\n",
      "       759         113.5033          -0.0086           33.47m\n",
      "       760         112.1053          -0.4298           33.33m\n",
      "       761         112.3814          -0.0463           33.19m\n",
      "       762         112.4723          -0.0277           33.06m\n",
      "       763         111.4105          -0.0169           32.93m\n",
      "       764         110.7543          -0.0456           32.78m\n",
      "       765         110.4629          -0.0471           32.65m\n",
      "       766         110.0793          -0.0130           32.50m\n",
      "       767         108.0561          -0.4374           32.36m\n",
      "       768         108.6816          -0.0222           32.22m\n",
      "       769         107.8796          -0.0616           32.08m\n",
      "       770         106.8201          -0.0315           31.93m\n",
      "       771         106.7779          -0.0109           31.79m\n",
      "       772         105.7295          -0.0109           31.65m\n",
      "       773         105.0906          -0.0263           31.51m\n",
      "       774         104.7173          -0.0247           31.37m\n",
      "       775         103.9635          -0.4478           31.23m\n",
      "       776         103.7184          -0.0351           31.09m\n",
      "       777         103.4282          -0.0002           30.96m\n",
      "       778         102.7548          -0.0142           30.83m\n",
      "       779         102.9753           0.0067           30.69m\n",
      "       780         101.2736          -0.0349           30.55m\n",
      "       781         101.4375          -0.0462           30.41m\n",
      "       782         100.6174          -0.0332           30.26m\n",
      "       783          99.9385          -0.0109           30.12m\n",
      "       784          98.7719          -0.4419           29.98m\n",
      "       785          99.5851          -0.0309           29.85m\n",
      "       786          98.7094          -0.0527           29.71m\n",
      "       787          97.0414          -0.4385           29.57m\n",
      "       788          97.5607          -0.0273           29.43m\n",
      "       789          96.3934          -0.4197           29.29m\n",
      "       790          97.2457          -0.0404           29.15m\n",
      "       791          96.1782          -0.0250           29.01m\n",
      "       792          96.3092          -0.0224           28.87m\n",
      "       793          94.0482          -0.4327           28.73m\n",
      "       794          94.0758          -0.4721           28.59m\n",
      "       795          94.3741          -0.0348           28.45m\n",
      "       796          93.5118          -0.0360           28.32m\n",
      "       797          92.9849          -0.4364           28.18m\n",
      "       798          92.7039           0.0004           28.04m\n",
      "       799          92.7271          -0.0311           27.90m\n",
      "       800          92.3009          -0.0348           27.77m\n",
      "       801          91.7850          -0.0324           27.63m\n",
      "       802          90.8799          -0.0417           27.49m\n",
      "       803          89.2827          -0.4359           27.35m\n",
      "       804          90.1977          -0.0275           27.22m\n",
      "       805          90.1681           0.0008           27.08m\n",
      "       806          89.4768          -0.0285           26.94m\n",
      "       807          89.1028          -0.0200           26.80m\n",
      "       808          88.3130          -0.0257           26.66m\n",
      "       809          87.9280          -0.0070           26.53m\n",
      "       810          87.8846          -0.0236           26.38m\n",
      "       811          85.8693          -0.4371           26.25m\n",
      "       812          86.8044          -0.0270           26.11m\n",
      "       813          86.5060          -0.0264           25.98m\n",
      "       814          86.3401          -0.0349           25.84m\n",
      "       815          85.8466          -0.0250           25.70m\n",
      "       816          84.8783          -0.0127           25.56m\n",
      "       817          84.5376          -0.0429           25.42m\n",
      "       818          83.2439          -0.4440           25.28m\n",
      "       819          82.7438          -0.4636           25.14m\n",
      "       820          83.2244          -0.0182           25.00m\n",
      "       821          81.9261          -0.4157           24.86m\n",
      "       822          82.6647           0.0118           24.72m\n",
      "       823          82.2338          -0.0174           24.59m\n",
      "       824          81.6439          -0.0239           24.45m\n",
      "       825          80.0815          -0.0191           24.31m\n",
      "       826          80.7715          -0.0260           24.17m\n",
      "       827          80.4405           0.0006           24.02m\n",
      "       828          79.7204          -0.0146           23.88m\n",
      "       829          77.9961          -0.4454           23.74m\n",
      "       830          78.9400          -0.0196           23.60m\n",
      "       831          77.3388          -0.4195           23.47m\n",
      "       832          78.3669          -0.0199           23.33m\n",
      "       833          77.6034          -0.0276           23.19m\n",
      "       834          76.4358          -0.4521           23.05m\n",
      "       835          76.0675          -0.4174           22.92m\n",
      "       836          76.9845          -0.0123           22.77m\n",
      "       837          76.2021          -0.0191           22.64m\n",
      "       838          75.2947          -0.4427           22.50m\n",
      "       839          75.8464          -0.0093           22.36m\n",
      "       840          74.4399          -0.4356           22.22m\n",
      "       841          75.0356          -0.0180           22.08m\n",
      "       842          74.6443          -0.0314           21.95m\n",
      "       843          73.2989          -0.4520           21.81m\n",
      "       844          73.8654          -0.0280           21.67m\n",
      "       845          73.3460          -0.0142           21.54m\n",
      "       846          73.5429          -0.0151           21.39m\n",
      "       847          72.8505          -0.0111           21.25m\n",
      "       848          72.2831          -0.0310           21.11m\n",
      "       849          72.0448          -0.0132           20.97m\n",
      "       850          71.6326          -0.0176           20.83m\n",
      "       851          71.2527          -0.0325           20.69m\n",
      "       852          70.4296          -0.4419           20.55m\n",
      "       853          69.4154          -0.3858           20.41m\n",
      "       854          70.4534          -0.0262           20.28m\n",
      "       855          68.7738          -0.4159           20.14m\n",
      "       856          69.6461          -0.0335           20.00m\n",
      "       857          69.5340          -0.0240           19.86m\n",
      "       858          69.0509          -0.0122           19.72m\n",
      "       859          68.6450          -0.0187           19.59m\n",
      "       860          68.5609          -0.0185           19.44m\n",
      "       861          68.1896          -0.0196           19.30m\n",
      "       862          68.0843          -0.0177           19.16m\n",
      "       863          67.1796          -0.0159           19.02m\n",
      "       864          67.3560          -0.0405           18.88m\n",
      "       865          65.7298          -0.4413           18.74m\n",
      "       866          66.5737          -0.0130           18.60m\n",
      "       867          65.3046          -0.4625           18.47m\n",
      "       868          65.9095          -0.0260           18.33m\n",
      "       869          65.6654          -0.0210           18.19m\n",
      "       870          65.5390          -0.0104           18.05m\n",
      "       871          65.1236          -0.0116           17.91m\n",
      "       872          64.7433          -0.0012           17.77m\n",
      "       873          63.4886          -0.4230           17.63m\n",
      "       874          64.1723          -0.0237           17.50m\n",
      "       875          62.8585          -0.4633           17.36m\n",
      "       876          63.3702          -0.0105           17.22m\n",
      "       877          63.1789          -0.0009           17.08m\n",
      "       878          62.9341          -0.0189           16.94m\n",
      "       879          61.9868          -0.0265           16.80m\n",
      "       880          62.2494          -0.0138           16.66m\n",
      "       881          61.9157          -0.0072           16.52m\n",
      "       882          61.2557          -0.0093           16.38m\n",
      "       883          61.3220          -0.0271           16.24m\n",
      "       884          59.8280          -0.4262           16.10m\n",
      "       885          60.3407          -0.0180           15.97m\n",
      "       886          60.2681          -0.0230           15.83m\n",
      "       887          59.8055          -0.0332           15.69m\n",
      "       888          58.6840          -0.4339           15.55m\n",
      "       889          59.4760          -0.0234           15.41m\n",
      "       890          59.2440          -0.0156           15.27m\n",
      "       891          58.9372          -0.0125           15.13m\n",
      "       892          58.5212          -0.0145           14.99m\n",
      "       893          58.3339          -0.0203           14.86m\n",
      "       894          57.8806          -0.0247           14.72m\n",
      "       895          57.7316          -0.0257           14.58m\n",
      "       896          57.7934          -0.0113           14.44m\n",
      "       897          57.2095           0.0018           14.30m\n",
      "       898          56.9779          -0.0171           14.16m\n",
      "       899          56.5844          -0.0240           14.02m\n",
      "       900          55.3364          -0.4349           13.89m\n",
      "       901          55.9409          -0.0000           13.75m\n",
      "       902          55.6694          -0.0087           13.61m\n",
      "       903          55.5800          -0.0118           13.47m\n",
      "       904          55.1583          -0.0106           13.34m\n",
      "       905          55.0264          -0.0034           13.20m\n",
      "       906          53.2794          -0.4437           13.06m\n",
      "       907          54.3386          -0.0246           12.92m\n",
      "       908          54.3124          -0.0127           12.78m\n",
      "       909          52.4899          -0.0005           12.64m\n",
      "       910          53.4196          -0.0185           12.50m\n",
      "       911          53.1495          -0.0233           12.36m\n",
      "       912          52.9741          -0.0084           12.22m\n",
      "       913          52.9319          -0.0103           12.08m\n",
      "       914          51.6397          -0.4301           11.94m\n",
      "       915          51.0689          -0.4279           11.81m\n",
      "       916          52.2856          -0.0167           11.67m\n",
      "       917          51.8323          -0.0223           11.53m\n",
      "       918          51.7189          -0.0082           11.39m\n",
      "       919          50.3696          -0.4149           11.25m\n",
      "       920          51.2389          -0.0193           11.11m\n",
      "       921          50.8471          -0.0147           10.98m\n",
      "       922          50.6793          -0.0089           10.84m\n",
      "       923          50.5841          -0.0069           10.70m\n",
      "       924          49.7590          -0.0187           10.56m\n",
      "       925          50.0884          -0.0072           10.42m\n",
      "       926          49.6614          -0.0222           10.28m\n",
      "       927          49.4020           0.0013           10.14m\n",
      "       928          48.9558          -0.0199           10.00m\n",
      "       929          48.9361          -0.0161            9.86m\n",
      "       930          47.0136          -0.0134            9.72m\n",
      "       931          48.3527          -0.0172            9.59m\n",
      "       932          48.0391          -0.0149            9.45m\n",
      "       933          47.5849          -0.0244            9.31m\n",
      "       934          46.7058          -0.4344            9.17m\n",
      "       935          47.4417          -0.0078            9.03m\n",
      "       936          47.2787          -0.0080            8.89m\n",
      "       937          45.6771          -0.4459            8.75m\n",
      "       938          46.5768          -0.0201            8.61m\n",
      "       939          46.3246          -0.0112            8.47m\n",
      "       940          46.3742          -0.0109            8.34m\n",
      "       941          45.1074          -0.4334            8.20m\n",
      "       942          45.7773          -0.0204            8.06m\n",
      "       943          45.5517          -0.0199            7.92m\n",
      "       944          45.1764          -0.0009            7.78m\n",
      "       945          44.8186          -0.0057            7.64m\n",
      "       946          44.6985           0.0013            7.50m\n",
      "       947          44.4856          -0.0112            7.36m\n",
      "       948          44.2721          -0.0264            7.22m\n",
      "       949          44.2948          -0.0192            7.08m\n",
      "       950          43.1048          -0.4436            6.95m\n",
      "       951          43.8353          -0.0027            6.81m\n",
      "       952          43.6790          -0.0141            6.67m\n",
      "       953          42.4495          -0.4341            6.53m\n",
      "       954          43.3260          -0.0121            6.39m\n",
      "       955          43.1165          -0.0231            6.25m\n",
      "       956          42.9529          -0.0171            6.11m\n",
      "       957          42.5686          -0.0039            5.97m\n",
      "       958          42.6174          -0.0076            5.83m\n",
      "       959          42.2922          -0.0083            5.69m\n",
      "       960          42.0658          -0.0232            5.55m\n",
      "       961          41.8194          -0.0199            5.42m\n",
      "       962          41.4627          -0.0135            5.28m\n",
      "       963          41.3570          -0.0127            5.14m\n",
      "       964          39.8312          -0.4507            5.00m\n",
      "       965          41.1198          -0.0122            4.86m\n",
      "       966          40.7785          -0.0183            4.72m\n",
      "       967          39.6270          -0.4541            4.58m\n",
      "       968          40.5462          -0.0092            4.44m\n",
      "       969          40.3132          -0.0134            4.30m\n",
      "       970          39.9956          -0.0074            4.17m\n",
      "       971          39.8423          -0.0040            4.03m\n",
      "       972          39.6512          -0.0111            3.89m\n",
      "       973          39.5409          -0.0064            3.75m\n",
      "       974          39.1003          -0.0077            3.61m\n",
      "       975          38.0689          -0.4304            3.47m\n",
      "       976          38.8812          -0.0061            3.33m\n",
      "       977          38.5721          -0.0224            3.19m\n",
      "       978          38.7029          -0.0085            3.05m\n",
      "       979          37.3078          -0.4304            2.92m\n",
      "       980          38.4172          -0.0056            2.78m\n",
      "       981          38.0538          -0.0086            2.64m\n",
      "       982          36.9642          -0.4221            2.50m\n",
      "       983          38.0363          -0.0127            2.36m\n",
      "       984          37.5686          -0.0150            2.22m\n",
      "       985          36.1440          -0.4233            2.08m\n",
      "       986          37.3982          -0.0079            1.94m\n",
      "       987          37.1779          -0.0123            1.81m\n",
      "       988          36.8329          -0.0192            1.67m\n",
      "       989          35.7979          -0.4524            1.53m\n",
      "       990          36.7086          -0.0033            1.39m\n",
      "       991          36.4187          -0.0073            1.25m\n",
      "       992          36.1798          -0.0118            1.11m\n",
      "       993          36.2486          -0.0072           58.38s\n",
      "       994          35.8734          -0.0177           50.03s\n",
      "       995          35.6241          -0.0047           41.69s\n",
      "       996          35.6566          -0.0071           33.34s\n",
      "       997          35.2864          -0.0101           25.00s\n",
      "       998          35.1983          -0.0140           16.67s\n",
      "       999          34.7412          -0.0141            8.33s\n",
      "      1000          34.7412          -0.0128            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.265159939001,\n",
       "              loss='deviance', max_depth=5, max_features=None,\n",
       "              max_leaf_nodes=12, min_samples_leaf=10, min_samples_split=10,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              presort='auto', random_state=21, subsample=0.884928788086,\n",
       "              verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_ivq_GBC.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init': None,\n",
       " 'learning_rate': 0.2651599390014479,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 5,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 12,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 10,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1000,\n",
       " 'presort': 'auto',\n",
       " 'random_state': 21,\n",
       " 'subsample': 0.8849287880855492,\n",
       " 'verbose': 2,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_ivq_GBC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "num_estimators = new_model_ivq_GBC.get_params()['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9cf8236410>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9cf8505150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, y_pred in zip(range(1, num_estimators+1), new_model_ivq_GBC.staged_predict(X_test)):\n",
    "    f1_scores.append(f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='weighted', sample_weight=None))\n",
    "\n",
    "plt.plot(f1_scores, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../models/model_GBC_IVQ_1000.pkl', 'w') as f:\n",
    "    pickle.dump(new_model_ivq_GBC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iter_search = 30\n",
    "random_search_SVC = RandomizedSearchCV(estimator=model_ivq_SVC,\n",
    "                                                   param_distributions=param_distributions['SVC'],\n",
    "                                                   n_iter=n_iter_search,\n",
    "                                                   n_jobs=36, cv=5, verbose=2, random_state=30, error_score='raise')\n",
    "random_search_SVC.fit(X_train, y_train['image_views_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_SVC = random_search_SVC.best_estimator_\n",
    "y_pred = best_SVC.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_views_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image nComments Quantile (ICQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_distributions = {'Logistic': {\"C\": sp_expon(loc=0.001, scale=1),\n",
    "                                    \"fit_intercept\": [True, False],\n",
    "                                    \"intercept_scaling\": sp_randint(1, 5),\n",
    "                                    \"warm_start\": [False, True]\n",
    "                                    },\n",
    "                       'RandomForest': {\"max_depth\": None,\n",
    "                                        \"max_features\": ['auto', None],\n",
    "                                        \"min_samples_split\": sp_randint(1, 201),\n",
    "                                        \"min_samples_leaf\": sp_randint(1, 201),\n",
    "                                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "                                        \"oob_score\": True,\n",
    "                                        \"warm_start\": [False, True] \n",
    "                                        },\n",
    "                       'AdaBoost_DT': {\"learning_rate\": sp_expon(loc=0.001, scale=1.5),\n",
    "                                       \"algorithm\" : ['SAMME.R', 'SAMME']\n",
    "                                       },\n",
    "                       'GBC': {\"learning_rate\": sp_expon(loc=0.001, scale=0.5),\n",
    "                               \"subsample\": sp_uniform(loc=0.2, scale=0.8),\n",
    "                               \"max_features\": [None, 'auto'],\n",
    "                               \"warm_start\": [True, False],\n",
    "                               \"max_depth\": [3, 4, 5],\n",
    "                               },\n",
    "                       'SVC': {\"C\": sp_expon(loc=0.001, scale=2),\n",
    "                               \"kernel\": ['rbf', 'poly'],\n",
    "                               \"degree\": sp_randint(2, 10),\n",
    "                               \"coef0\": [0, 1, 2],\n",
    "                               \"shrinking\": [True, False]\n",
    "                               }\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Models (ICQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=4, min_samples_split=10, min_samples_leaf=10,\n",
    "      min_weight_fraction_leaf=0.0, max_features=300, random_state=30, max_leaf_nodes=20, class_weight=None,\n",
    "      presort=False)\n",
    "\n",
    "model_icq_LogitClassifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001,\n",
    "                                               class_weight=None, random_state=25,\n",
    "                                               solver='liblinear', max_iter=1000, multi_class='ovr', verbose=2,\n",
    "                                               n_jobs=36)\n",
    "\n",
    "model_icq_RandomForest = RandomForestClassifier(n_estimators=1000, min_weight_fraction_leaf=0.0, n_jobs=36,\n",
    "                                                random_state=42, verbose=2, class_weight=None, bootstrap=True)\n",
    "\n",
    "model_icq_AdaBoost_DT = AdaBoostClassifier(base_estimator=DT, n_estimators=300, random_state=12)\n",
    "\n",
    "model_icq_GBC = GradientBoostingClassifier(loss='deviance', n_estimators=100,\n",
    "                                           min_samples_split=10, min_samples_leaf=10, min_weight_fraction_leaf=0.0,\n",
    "                                           random_state=21, verbose=0,\n",
    "                                           max_leaf_nodes=12, presort='auto')\n",
    "\n",
    "model_icq_SVC = SVC(gamma='auto', probability=True,\n",
    "                    tol=0.001, cache_size=1000, class_weight=None, verbose=True, max_iter=-1,\n",
    "                    decision_function_shape='ovr', random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB Classifier Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "n_iter_search = 20\n",
    "random_search_GBC = RandomizedSearchCV(estimator=model_icq_GBC,\n",
    "                                       param_distributions=param_distributions['GBC'],\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       n_jobs=36, cv=3, verbose=1, random_state=30, error_score='raise')\n",
    "random_search_GBC.fit(X_train, y_train['image_ncomments_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search_GBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_GBC = random_search_GBC.best_estimator_\n",
    "y_pred = best_GBC.predict(X_test)\n",
    "print \"Best AdaBoost DT F1 Score: \", f1_score(y_test['image_ncomments_quantile'], y_pred, labels=None, pos_label=None, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_params = best_GBC.get_params()\n",
    "new_params['n_estimators'] = 1000\n",
    "new_params['verbose'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model_icq_GBC = GradientBoostingClassifier(**new_params)\n",
    "new_model_icq_GBC.fit(X_train, y_train['image_ncomments_quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model_icq_GBC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "num_estimators = new_model_icq_GBC.get_params()['n_estimators']\n",
    "for i, y_pred in zip(range(1, num_estimators+1), new_model_icq_GBC.staged_predict(X_test)):\n",
    "    f1_scores.append(f1_score(y_test['image_ncomments_quantile'], y_pred, labels=None, pos_label=None, average='weighted', sample_weight=None))\n",
    "\n",
    "plt.plot(f1_scores, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH - Image nFavs Quantile (InFQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv = sp_expon(loc=0.001, scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rv.rvs(1000), bins=40)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = rv.rvs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
